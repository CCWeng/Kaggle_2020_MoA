{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_SET = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(labels, preds):\n",
    "    return -1 * np.mean(labels * np.log(preds) + (1 - labels) * np.log(1 - preds))\n",
    "\n",
    "def clip_preds(preds):\n",
    "    return np.maximum(np.minimum(preds, 1 - 1e-15), 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = '../_data/lish-moa'\n",
    "\n",
    "trn_feat = pd.read_csv(os.path.join(input_dir, 'train_features.csv'))\n",
    "tst_feat = pd.read_csv(os.path.join(input_dir, 'test_features.csv'))\n",
    "target_scored = pd.read_csv(os.path.join(input_dir, 'train_targets_scored.csv'))\n",
    "target_nonscored = pd.read_csv(os.path.join(input_dir, 'train_targets_nonscored.csv'))\n",
    "sub = pd.read_csv(os.path.join(input_dir, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    }
   ],
   "source": [
    "target_cols = [c for c in target_scored if c != 'sig_id']\n",
    "print(len(target_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'proteasome_inhibitor' in target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_feat.sort_values(by='sig_id', inplace=True)\n",
    "target_scored.sort_values(by='sig_id', inplace=True)\n",
    "target_nonscored.sort_values(by='sig_id', inplace=True)\n",
    "\n",
    "tst_feat.sort_values(by='sig_id', inplace=True)\n",
    "sub.sort_values(by='sig_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_columns = [c for c in trn_feat.columns if c.startswith('g-')]\n",
    "cell_columns = [c for c in trn_feat.columns if c.startswith('c-')]\n",
    "\n",
    "scored_columns = [c for c in target_scored.columns if c != 'sig_id']\n",
    "nonscored_columns = [c for c in target_nonscored.columns if c != 'sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_columns = ['cp_type', 'cp_time', 'cp_dose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfkb_inhibitor : positive rate = 0.03493743176282859\n"
     ]
    }
   ],
   "source": [
    "max_value = target_scored[scored_columns].mean().max()\n",
    "max_index = target_scored[scored_columns].mean().values.argmax()\n",
    "target = scored_columns[max_index]\n",
    "\n",
    "print(target, ': positive rate =', max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original majority(negative) : minority(positive) ratio is about **100 : 3**\n",
    "\n",
    "Thus, decompose the majority(negative) data into **20** smaller sets with sampling, such that the negative : positive rate will be about **5 : 3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression + Data decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation:\n",
    "1. Dummy coding\n",
    "2. train test split\n",
    "3. randomly decompose negative data set into 20 sets of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = trn_feat.set_index('sig_id')\n",
    "y = target_scored[['sig_id', target]].set_index('sig_id')[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dumm = pd.get_dummies(X, columns=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22982\n",
       "1      832\n",
       "Name: nfkb_inhibitor, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X_dumm, y, test_size=0.1, random_state=7)\n",
    "\n",
    "print(X_trn.shape, y_trn.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_index = y_trn.loc[y_trn == 1].index.tolist()\n",
    "neg_index = y_trn.loc[y_trn == 0].index.tolist()\n",
    "\n",
    "\n",
    "num_neg = len(neg_index)\n",
    "set_size = int(np.ceil(num_neg / NUM_SET))\n",
    "\n",
    "np.random.shuffle(neg_index)\n",
    "set_index_list = []\n",
    "\n",
    "for i in range(NUM_SET):\n",
    "    set_index_list.append(neg_index[i*set_size:(i+1)*set_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train weak classifiers\n",
    "* use logistic regression\n",
    "\n",
    "Assemble predictions and evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.2620353726377695\n",
      "Set 2 : set log-loss = 9.992007221626413e-16, valid log-loss = 1.9140299048717115\n",
      "Set 3 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.0880328065963507\n",
      "Set 4 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.001031355734031\n",
      "Set 5 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.044531745481971\n",
      "Set 6 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.044532081165191\n",
      "Set 7 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.117033625900344\n",
      "Set 8 : set log-loss = 9.992007221626413e-16, valid log-loss = 1.9720305364300381\n",
      "Set 9 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.4215390396016825\n",
      "Set 10 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.291035856258543\n",
      "Set 11 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.320037011245756\n",
      "Set 12 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.1895344992690573\n",
      "Set 13 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.2330355603834366\n",
      "Set 14 : set log-loss = 9.992007221626413e-16, valid log-loss = 1.9575306303028714\n",
      "Set 15 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.088033477962791\n",
      "Set 16 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.2475354665106035\n",
      "Set 17 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.247534795144163\n",
      "Set 18 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.146033773837897\n",
      "Set 19 : set log-loss = 9.992007221626413e-16, valid log-loss = 2.1315335320275106\n",
      "Set 20 : set log-loss = 9.992007221626413e-16, valid log-loss = 1.972030872113258\n",
      "\n",
      "Assemble valid log-loss = 0.25768089857052445\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "p_set_list = []\n",
    "p_val_list = []\n",
    "\n",
    "p_asm = np.zeros(len(y_val))\n",
    "\n",
    "for i in range(NUM_SET):\n",
    "    I = pos_index + set_index_list[i]\n",
    "    np.random.shuffle(I)\n",
    "    \n",
    "    X_set = X_trn.loc[I]\n",
    "    y_set = y_trn.loc[I]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_set, y_set)\n",
    "    \n",
    "    model_list.append(model)\n",
    "    \n",
    "    p_set = clip_preds(model.predict(X_set))\n",
    "    p_val = clip_preds(model.predict(X_val))\n",
    "    \n",
    "    logloss_set = log_loss(y_set, p_set)\n",
    "    logloss_val = log_loss(y_val, p_val)\n",
    "    \n",
    "    print(f'Set {i+1} : set log-loss = {logloss_set}, valid log-loss = {logloss_val}')\n",
    "    \n",
    "    p_asm += (p_val / NUM_SET)\n",
    "    p_set_list.append(p_set)\n",
    "    p_val_list.append(p_val)\n",
    "\n",
    "logloss_asm = log_loss(y_val, p_asm)\n",
    "print(f'\\nAssemble valid log-loss = {logloss_asm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025784827469139245 0.5655057380896574\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_trn, y_trn)\n",
    "\n",
    "p_trn = lr.predict(X_trn)\n",
    "p_val = lr.predict(X_val)\n",
    "\n",
    "p_trn = clip_preds(p_trn)\n",
    "p_val = clip_preds(p_val)\n",
    "\n",
    "logloss_trn = log_loss(y_trn, p_trn)\n",
    "logloss_val = log_loss(y_val, p_val)\n",
    "\n",
    "print(logloss_trn, logloss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = trn_feat.set_index('sig_id')\n",
    "y = target_scored[['sig_id', target]].set_index('sig_id')[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in cate_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[c] = le.fit_transform(X[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21432, 875) (21432,)\n",
      "(2382, 875) (2382,)\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.1, random_state=7)\n",
    "\n",
    "print(X_trn.shape, y_trn.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trn = lgb.Dataset(X_trn, label=y_trn, categorical_feature=cate_columns)\n",
    "D_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_freq': 1,\n",
    "    'pos_bagging_fraction': 0.9,\n",
    "    'neg_bagging_fraction': 0.05,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.020699\tvalid's binary_logloss: 0.0451419\n",
      "[100]\ttrain's binary_logloss: 0.00555636\tvalid's binary_logloss: 0.0456743\n",
      "[150]\ttrain's binary_logloss: 0.00332954\tvalid's binary_logloss: 0.0570163\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttrain's binary_logloss: 0.0114959\tvalid's binary_logloss: 0.0414787\n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.train(lgb_params, \n",
    "                      D_trn,\n",
    "#                       feval=log_loss_eval,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      categorical_feature=cate_columns,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_val = lgb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04147873474414674"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.0841334\tvalid's binary_logloss: 0.0883566\n",
      "[100]\ttrain's binary_logloss: 0.0713465\tvalid's binary_logloss: 0.0803146\n",
      "[150]\ttrain's binary_logloss: 0.0632966\tvalid's binary_logloss: 0.0750331\n",
      "[200]\ttrain's binary_logloss: 0.0566888\tvalid's binary_logloss: 0.0703303\n",
      "[250]\ttrain's binary_logloss: 0.0514041\tvalid's binary_logloss: 0.0667222\n",
      "[300]\ttrain's binary_logloss: 0.0466528\tvalid's binary_logloss: 0.063368\n",
      "[350]\ttrain's binary_logloss: 0.0425977\tvalid's binary_logloss: 0.060467\n",
      "[400]\ttrain's binary_logloss: 0.0388749\tvalid's binary_logloss: 0.0578954\n",
      "[450]\ttrain's binary_logloss: 0.0355341\tvalid's binary_logloss: 0.0556014\n",
      "[500]\ttrain's binary_logloss: 0.0324455\tvalid's binary_logloss: 0.0533664\n",
      "[550]\ttrain's binary_logloss: 0.0293914\tvalid's binary_logloss: 0.0514023\n",
      "[600]\ttrain's binary_logloss: 0.026363\tvalid's binary_logloss: 0.0495137\n",
      "[650]\ttrain's binary_logloss: 0.0237457\tvalid's binary_logloss: 0.0479993\n",
      "[700]\ttrain's binary_logloss: 0.0211914\tvalid's binary_logloss: 0.0465116\n",
      "[750]\ttrain's binary_logloss: 0.0187957\tvalid's binary_logloss: 0.0451935\n",
      "[800]\ttrain's binary_logloss: 0.016868\tvalid's binary_logloss: 0.0442271\n",
      "[850]\ttrain's binary_logloss: 0.0151592\tvalid's binary_logloss: 0.0433047\n",
      "[900]\ttrain's binary_logloss: 0.0137064\tvalid's binary_logloss: 0.0428209\n",
      "[950]\ttrain's binary_logloss: 0.012394\tvalid's binary_logloss: 0.0425477\n",
      "[1000]\ttrain's binary_logloss: 0.0110321\tvalid's binary_logloss: 0.042385\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's binary_logloss: 0.0110321\tvalid's binary_logloss: 0.042385\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 24,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_freq': 1,\n",
    "    'pos_bagging_fraction': 0.9,\n",
    "    'neg_bagging_fraction': 0.05,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params, \n",
    "                      D_trn,\n",
    "#                       feval=log_loss_eval,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      categorical_feature=cate_columns,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = trn_feat.set_index('sig_id')\n",
    "y = target_scored[['sig_id', target]].set_index('sig_id')[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_columns = ['cp_type', 'cp_dose']\n",
    "\n",
    "for c in cate_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[c] = le.fit_transform(X[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21432, 875) (21432,)\n",
      "(2382, 875) (2382,)\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.1, random_state=7)\n",
    "\n",
    "print(X_trn.shape, y_trn.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trn = lgb.Dataset(X_trn, label=y_trn, categorical_feature=cate_columns)\n",
    "D_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.0841334\tvalid's binary_logloss: 0.0883566\n",
      "[100]\ttrain's binary_logloss: 0.0713465\tvalid's binary_logloss: 0.0803146\n",
      "[150]\ttrain's binary_logloss: 0.0632966\tvalid's binary_logloss: 0.0750331\n",
      "[200]\ttrain's binary_logloss: 0.0566888\tvalid's binary_logloss: 0.0703303\n",
      "[250]\ttrain's binary_logloss: 0.0514041\tvalid's binary_logloss: 0.0667222\n",
      "[300]\ttrain's binary_logloss: 0.0466528\tvalid's binary_logloss: 0.063368\n",
      "[350]\ttrain's binary_logloss: 0.0425977\tvalid's binary_logloss: 0.060467\n",
      "[400]\ttrain's binary_logloss: 0.0388749\tvalid's binary_logloss: 0.0578954\n",
      "[450]\ttrain's binary_logloss: 0.0355341\tvalid's binary_logloss: 0.0556014\n",
      "[500]\ttrain's binary_logloss: 0.0324455\tvalid's binary_logloss: 0.0533664\n",
      "[550]\ttrain's binary_logloss: 0.0293914\tvalid's binary_logloss: 0.0514023\n",
      "[600]\ttrain's binary_logloss: 0.0263629\tvalid's binary_logloss: 0.0495136\n",
      "[650]\ttrain's binary_logloss: 0.0237491\tvalid's binary_logloss: 0.0479994\n",
      "[700]\ttrain's binary_logloss: 0.0211943\tvalid's binary_logloss: 0.0465125\n",
      "[750]\ttrain's binary_logloss: 0.0187956\tvalid's binary_logloss: 0.0451938\n",
      "[800]\ttrain's binary_logloss: 0.0168834\tvalid's binary_logloss: 0.0442428\n",
      "[850]\ttrain's binary_logloss: 0.0152104\tvalid's binary_logloss: 0.0432978\n",
      "[900]\ttrain's binary_logloss: 0.0137545\tvalid's binary_logloss: 0.0429267\n",
      "[950]\ttrain's binary_logloss: 0.0124654\tvalid's binary_logloss: 0.0425756\n",
      "[1000]\ttrain's binary_logloss: 0.0111891\tvalid's binary_logloss: 0.0423856\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's binary_logloss: 0.0111891\tvalid's binary_logloss: 0.0423856\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 24,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_freq': 1,\n",
    "    'pos_bagging_fraction': 0.9,\n",
    "    'neg_bagging_fraction': 0.05,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params, \n",
    "                      D_trn,\n",
    "#                       feval=log_loss_eval,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      categorical_feature=cate_columns,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0366142684401451"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "757 / 20675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.110134\tvalid's binary_logloss: 0.104069\n",
      "[20]\ttrain's binary_logloss: 0.0924821\tvalid's binary_logloss: 0.0893216\n",
      "[30]\ttrain's binary_logloss: 0.0811045\tvalid's binary_logloss: 0.0797725\n",
      "[40]\ttrain's binary_logloss: 0.0726612\tvalid's binary_logloss: 0.0728113\n",
      "[50]\ttrain's binary_logloss: 0.0660094\tvalid's binary_logloss: 0.0673988\n",
      "[60]\ttrain's binary_logloss: 0.0602744\tvalid's binary_logloss: 0.0630478\n",
      "[70]\ttrain's binary_logloss: 0.0553557\tvalid's binary_logloss: 0.0594301\n",
      "[80]\ttrain's binary_logloss: 0.0511256\tvalid's binary_logloss: 0.0563111\n",
      "[90]\ttrain's binary_logloss: 0.0473992\tvalid's binary_logloss: 0.0536005\n",
      "[100]\ttrain's binary_logloss: 0.0441221\tvalid's binary_logloss: 0.0513151\n",
      "[110]\ttrain's binary_logloss: 0.041306\tvalid's binary_logloss: 0.0494025\n",
      "[120]\ttrain's binary_logloss: 0.0386863\tvalid's binary_logloss: 0.0477562\n",
      "[130]\ttrain's binary_logloss: 0.0363933\tvalid's binary_logloss: 0.0463794\n",
      "[140]\ttrain's binary_logloss: 0.0342938\tvalid's binary_logloss: 0.0452002\n",
      "[150]\ttrain's binary_logloss: 0.0324198\tvalid's binary_logloss: 0.0442043\n",
      "[160]\ttrain's binary_logloss: 0.0307022\tvalid's binary_logloss: 0.0433106\n",
      "[170]\ttrain's binary_logloss: 0.0289216\tvalid's binary_logloss: 0.0425265\n",
      "[180]\ttrain's binary_logloss: 0.0273889\tvalid's binary_logloss: 0.0418194\n",
      "[190]\ttrain's binary_logloss: 0.0260611\tvalid's binary_logloss: 0.0412223\n",
      "[200]\ttrain's binary_logloss: 0.0247733\tvalid's binary_logloss: 0.040652\n",
      "[210]\ttrain's binary_logloss: 0.0235302\tvalid's binary_logloss: 0.0401053\n",
      "[220]\ttrain's binary_logloss: 0.0223595\tvalid's binary_logloss: 0.0396834\n",
      "[230]\ttrain's binary_logloss: 0.0212899\tvalid's binary_logloss: 0.0393181\n",
      "[240]\ttrain's binary_logloss: 0.020304\tvalid's binary_logloss: 0.0390344\n",
      "[250]\ttrain's binary_logloss: 0.0193856\tvalid's binary_logloss: 0.0387517\n",
      "[260]\ttrain's binary_logloss: 0.0185354\tvalid's binary_logloss: 0.0384373\n",
      "[270]\ttrain's binary_logloss: 0.0177034\tvalid's binary_logloss: 0.0382004\n",
      "[280]\ttrain's binary_logloss: 0.0169374\tvalid's binary_logloss: 0.0380266\n",
      "[290]\ttrain's binary_logloss: 0.016185\tvalid's binary_logloss: 0.0377563\n",
      "[300]\ttrain's binary_logloss: 0.0154853\tvalid's binary_logloss: 0.0375515\n",
      "[310]\ttrain's binary_logloss: 0.0147797\tvalid's binary_logloss: 0.0374589\n",
      "[320]\ttrain's binary_logloss: 0.0140044\tvalid's binary_logloss: 0.0373289\n",
      "[330]\ttrain's binary_logloss: 0.0133067\tvalid's binary_logloss: 0.0372431\n",
      "[340]\ttrain's binary_logloss: 0.0127208\tvalid's binary_logloss: 0.0371646\n",
      "[350]\ttrain's binary_logloss: 0.0121554\tvalid's binary_logloss: 0.0370542\n",
      "[360]\ttrain's binary_logloss: 0.0116573\tvalid's binary_logloss: 0.0370597\n",
      "[370]\ttrain's binary_logloss: 0.0111002\tvalid's binary_logloss: 0.0369979\n",
      "[380]\ttrain's binary_logloss: 0.010558\tvalid's binary_logloss: 0.0369683\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttrain's binary_logloss: 0.0105917\tvalid's binary_logloss: 0.0369548\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 24,\n",
    "    'min_data_in_leaf': 20,\n",
    "#     'bagging_freq': 1,\n",
    "#     'pos_bagging_fraction': 0.9,\n",
    "#     'neg_bagging_fraction': 0.03,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params, \n",
    "                      D_trn,\n",
    "#                       feval=log_loss_eval,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      categorical_feature=cate_columns,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=10,\n",
    "                      verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttrain's binary_logloss: 0.109985\tvalid's binary_logloss: 0.104051\n",
      "[20]\ttrain's binary_logloss: 0.0922511\tvalid's binary_logloss: 0.0892996\n",
      "[30]\ttrain's binary_logloss: 0.0807549\tvalid's binary_logloss: 0.0797091\n",
      "[40]\ttrain's binary_logloss: 0.072133\tvalid's binary_logloss: 0.0727466\n",
      "[50]\ttrain's binary_logloss: 0.0653025\tvalid's binary_logloss: 0.0673386\n",
      "[60]\ttrain's binary_logloss: 0.0592286\tvalid's binary_logloss: 0.0625983\n",
      "[70]\ttrain's binary_logloss: 0.0540691\tvalid's binary_logloss: 0.0588917\n",
      "[80]\ttrain's binary_logloss: 0.0494766\tvalid's binary_logloss: 0.0558522\n",
      "[90]\ttrain's binary_logloss: 0.045313\tvalid's binary_logloss: 0.0532503\n",
      "[100]\ttrain's binary_logloss: 0.0416544\tvalid's binary_logloss: 0.0509662\n",
      "[110]\ttrain's binary_logloss: 0.0383054\tvalid's binary_logloss: 0.0490338\n",
      "[120]\ttrain's binary_logloss: 0.0352944\tvalid's binary_logloss: 0.0474\n",
      "[130]\ttrain's binary_logloss: 0.0324737\tvalid's binary_logloss: 0.0459623\n",
      "[140]\ttrain's binary_logloss: 0.0298719\tvalid's binary_logloss: 0.0447412\n",
      "[150]\ttrain's binary_logloss: 0.0276435\tvalid's binary_logloss: 0.0436662\n",
      "[160]\ttrain's binary_logloss: 0.0256135\tvalid's binary_logloss: 0.0428172\n",
      "[170]\ttrain's binary_logloss: 0.0235059\tvalid's binary_logloss: 0.0419274\n",
      "[180]\ttrain's binary_logloss: 0.021604\tvalid's binary_logloss: 0.0411436\n",
      "[190]\ttrain's binary_logloss: 0.0200183\tvalid's binary_logloss: 0.0405859\n",
      "[200]\ttrain's binary_logloss: 0.0185169\tvalid's binary_logloss: 0.0400837\n",
      "[210]\ttrain's binary_logloss: 0.0172169\tvalid's binary_logloss: 0.0397083\n",
      "[220]\ttrain's binary_logloss: 0.0160042\tvalid's binary_logloss: 0.0393697\n",
      "[230]\ttrain's binary_logloss: 0.0148572\tvalid's binary_logloss: 0.0389985\n",
      "[240]\ttrain's binary_logloss: 0.0138394\tvalid's binary_logloss: 0.0387257\n",
      "[250]\ttrain's binary_logloss: 0.0129212\tvalid's binary_logloss: 0.0385246\n",
      "[260]\ttrain's binary_logloss: 0.0120706\tvalid's binary_logloss: 0.0383457\n",
      "[270]\ttrain's binary_logloss: 0.0112499\tvalid's binary_logloss: 0.0382272\n",
      "[280]\ttrain's binary_logloss: 0.0104711\tvalid's binary_logloss: 0.0381586\n",
      "[290]\ttrain's binary_logloss: 0.00974307\tvalid's binary_logloss: 0.0380561\n",
      "[300]\ttrain's binary_logloss: 0.00905668\tvalid's binary_logloss: 0.0380042\n",
      "[310]\ttrain's binary_logloss: 0.00842573\tvalid's binary_logloss: 0.0379549\n",
      "[320]\ttrain's binary_logloss: 0.00785984\tvalid's binary_logloss: 0.0378765\n",
      "[330]\ttrain's binary_logloss: 0.00735537\tvalid's binary_logloss: 0.0378615\n",
      "Early stopping, best iteration is:\n",
      "[327]\ttrain's binary_logloss: 0.00749824\tvalid's binary_logloss: 0.037835\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 20,\n",
    "#     'bagging_freq': 1,\n",
    "#     'pos_bagging_fraction': 0.9,\n",
    "#     'neg_bagging_fraction': 0.05,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params, \n",
    "                      D_trn,\n",
    "#                       feval=log_loss_eval,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      categorical_feature=cate_columns,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=10,\n",
    "                      verbose_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 LightGBM + decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 24,\n",
    "    'min_data_in_leaf': 20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_index = y_trn.loc[y_trn == 1].index.tolist()\n",
    "neg_index = y_trn.loc[y_trn == 0].index.tolist()\n",
    "\n",
    "\n",
    "num_neg = len(neg_index)\n",
    "set_size = int(np.ceil(num_neg / NUM_SET))\n",
    "\n",
    "np.random.shuffle(neg_index)\n",
    "set_index_list = []\n",
    "\n",
    "for i in range(NUM_SET):\n",
    "    set_index_list.append(neg_index[i*set_size:(i+1)*set_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_set = lgb.Dataset(X_set, label=y_set, categorical_feature=cate_columns)\n",
    "D_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set 1 : set log-loss = 0.004289107910202883, valid log-loss = 0.05612985476182848\n",
      "Set 2 : set log-loss = 0.0037411831792250614, valid log-loss = 0.054099959021151084\n",
      "Set 3 : set log-loss = 0.0055184935463940465, valid log-loss = 0.06426306119833129\n",
      "Set 4 : set log-loss = 0.004808982671179445, valid log-loss = 0.06272048137819665\n",
      "Set 5 : set log-loss = 0.004948970900312611, valid log-loss = 0.061710800569027675\n",
      "Set 6 : set log-loss = 0.005100795274953932, valid log-loss = 0.06366805465172382\n",
      "Set 7 : set log-loss = 0.004330591421659294, valid log-loss = 0.05847215936703586\n",
      "Set 8 : set log-loss = 0.003984518829946974, valid log-loss = 0.05245457268197694\n",
      "Set 9 : set log-loss = 0.004176529181024854, valid log-loss = 0.055255215136066134\n",
      "Set 10 : set log-loss = 0.005113914430399332, valid log-loss = 0.057313768528676444\n",
      "Set 11 : set log-loss = 0.0035720278631830625, valid log-loss = 0.05457176023298788\n",
      "Set 12 : set log-loss = 0.0053681960245931925, valid log-loss = 0.05547713574104806\n",
      "Set 13 : set log-loss = 0.004316599234780449, valid log-loss = 0.0568563656522586\n",
      "Set 14 : set log-loss = 0.004063018658116421, valid log-loss = 0.05870658394376813\n",
      "Set 15 : set log-loss = 0.002854944021856721, valid log-loss = 0.05539369506856428\n",
      "Set 16 : set log-loss = 0.003531723075789734, valid log-loss = 0.05262169339100219\n",
      "Set 17 : set log-loss = 0.0033750110231792222, valid log-loss = 0.05644735383027745\n",
      "Set 18 : set log-loss = 0.003106411612346873, valid log-loss = 0.0527213800071845\n",
      "Set 19 : set log-loss = 0.004245500775109216, valid log-loss = 0.05636519236772688\n",
      "Set 20 : set log-loss = 0.004445811381814221, valid log-loss = 0.058261659379123115\n",
      "\n",
      "Assemble valid log-loss = 0.05196274862341825\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 24,\n",
    "    'min_data_in_leaf': 20,\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "p_set_list = []\n",
    "p_val_list = []\n",
    "\n",
    "p_asm = np.zeros(len(y_val))\n",
    "\n",
    "for i in range(NUM_SET):\n",
    "    I = pos_index + set_index_list[i]\n",
    "    np.random.shuffle(I)\n",
    "    \n",
    "    X_set = X_trn.loc[I]\n",
    "    y_set = y_trn.loc[I]\n",
    "    \n",
    "    D_set = lgb.Dataset(X_set, label=y_set, categorical_feature=cate_columns)\n",
    "    D_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cate_columns)\n",
    "    \n",
    "    model = lgb.train(lgb_params, \n",
    "                      D_set,\n",
    "                      valid_sets=[D_set, D_val],\n",
    "                      valid_names=['set', 'valid'],\n",
    "                      num_boost_round=1500,\n",
    "                      early_stopping_rounds=10,\n",
    "                      verbose_eval=0,\n",
    "                     )\n",
    "    \n",
    "    \n",
    "    model_list.append(model)\n",
    "    \n",
    "    p_set = clip_preds(model.predict(X_set))\n",
    "    p_val = clip_preds(model.predict(X_val))\n",
    "    \n",
    "    logloss_set = log_loss(y_set, p_set)\n",
    "    logloss_val = log_loss(y_val, p_val)\n",
    "    \n",
    "    print(f'Set {i+1} : set log-loss = {logloss_set}, valid log-loss = {logloss_val}')\n",
    "    \n",
    "    p_asm += (p_val / NUM_SET)\n",
    "    p_set_list.append(p_set)\n",
    "    p_val_list.append(p_val)\n",
    "\n",
    "logloss_asm = log_loss(y_val, p_asm)\n",
    "print(f'\\nAssemble valid log-loss = {logloss_asm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1400945659690275"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_val, np.ones(len(y_val)) * y_trn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 537 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/wcc/01_Projects/04_Practice/05_GAN/venv3/lib/python3.7/site-packages (from imbalanced-learn) (1.18.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/wcc/01_Projects/04_Practice/05_GAN/venv3/lib/python3.7/site-packages (from imbalanced-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/wcc/01_Projects/04_Practice/05_GAN/venv3/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Collecting scikit-learn>=0.23\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22\n",
      "    Uninstalling scikit-learn-0.22:\n",
      "      Successfully uninstalled scikit-learn-0.22\n",
      "Successfully installed imbalanced-learn-0.7.0 scikit-learn-0.23.2 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/wcc/01_Projects/04_Practice/05_GAN/venv3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Over-sampling : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = trn_feat.set_index('sig_id')\n",
    "y = target_scored[['sig_id', target]].set_index('sig_id')[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21432, 879) (21432,)\n",
      "(2382, 879) (2382,)\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.1, random_state=7)\n",
    "\n",
    "print(X_trn.shape, y_trn.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41350, 879) (41350,)\n",
      "1    20675\n",
      "0    20675\n",
      "Name: nfkb_inhibitor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE()\n",
    "X_smote, y_smote = smote.fit_resample(X_trn, y_trn)\n",
    "\n",
    "print(X_smote.shape, y_smote.shape)\n",
    "print(y_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41350, 879) (2382, 879)\n"
     ]
    }
   ],
   "source": [
    "print(X_smote.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trn = lgb.Dataset(X_smote, label=y_smote)\n",
    "D_val = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.0209663\tvalid's binary_logloss: 0.0456096\n",
      "[100]\ttrain's binary_logloss: 0.00177925\tvalid's binary_logloss: 0.0412781\n",
      "[150]\ttrain's binary_logloss: 0.000136117\tvalid's binary_logloss: 0.0562002\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttrain's binary_logloss: 0.00570875\tvalid's binary_logloss: 0.0386952\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      D_trn,\n",
    "                      valid_sets=[D_trn, D_val],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn2, X_val2, y_trn2, y_val2 = train_test_split(X_smote, y_smote, test_size=0.3, random_state=7)\n",
    "\n",
    "D_trn2 = lgb.Dataset(X_trn2, label=y_trn2)\n",
    "D_val2 = lgb.Dataset(X_val2, label=y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.131876\tvalid's binary_logloss: 0.13129\n",
      "[100]\ttrain's binary_logloss: 0.0618685\tvalid's binary_logloss: 0.0644141\n",
      "[150]\ttrain's binary_logloss: 0.0350784\tvalid's binary_logloss: 0.0392938\n",
      "[200]\ttrain's binary_logloss: 0.0204008\tvalid's binary_logloss: 0.0248492\n",
      "[250]\ttrain's binary_logloss: 0.0121188\tvalid's binary_logloss: 0.0165397\n",
      "[300]\ttrain's binary_logloss: 0.00725927\tvalid's binary_logloss: 0.011282\n",
      "[350]\ttrain's binary_logloss: 0.00440663\tvalid's binary_logloss: 0.00805343\n",
      "[400]\ttrain's binary_logloss: 0.00280007\tvalid's binary_logloss: 0.00614296\n",
      "[450]\ttrain's binary_logloss: 0.00185131\tvalid's binary_logloss: 0.0048661\n",
      "[500]\ttrain's binary_logloss: 0.00128808\tvalid's binary_logloss: 0.00404823\n",
      "[550]\ttrain's binary_logloss: 0.000971803\tvalid's binary_logloss: 0.00358695\n",
      "[600]\ttrain's binary_logloss: 0.000766942\tvalid's binary_logloss: 0.00323616\n",
      "[650]\ttrain's binary_logloss: 0.000633184\tvalid's binary_logloss: 0.00300701\n",
      "[700]\ttrain's binary_logloss: 0.000542455\tvalid's binary_logloss: 0.00286149\n",
      "[750]\ttrain's binary_logloss: 0.000479267\tvalid's binary_logloss: 0.0027347\n",
      "[800]\ttrain's binary_logloss: 0.000433316\tvalid's binary_logloss: 0.00263924\n",
      "[850]\ttrain's binary_logloss: 0.000401256\tvalid's binary_logloss: 0.00257247\n",
      "[900]\ttrain's binary_logloss: 0.000399175\tvalid's binary_logloss: 0.00257382\n",
      "[950]\ttrain's binary_logloss: 0.000399175\tvalid's binary_logloss: 0.00257382\n",
      "Early stopping, best iteration is:\n",
      "[850]\ttrain's binary_logloss: 0.000401256\tvalid's binary_logloss: 0.00257247\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 40,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      D_trn2,\n",
    "                      valid_sets=[D_trn2, D_val2],\n",
    "                      valid_names=['train', 'valid'],\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Over-sampling + Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25445, 879) (25445,)\n",
      "1    20675\n",
      "0     4770\n",
      "Name: nfkb_inhibitor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_smoteenn, y_smoteenn = smote_enn.fit_resample(X_trn, y_trn)\n",
    "\n",
    "print(X_smoteenn.shape, y_smoteenn.shape)\n",
    "print(y_smoteenn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trn = lgb.Dataset(X_smoteenn, label=y_smoteenn)\n",
    "D_val = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.00876124\tvalid's binary_logloss: 0.721482\n",
      "[100]\ttrain's binary_logloss: 0.000834782\tvalid's binary_logloss: 0.570969\n",
      "[150]\ttrain's binary_logloss: 0.000132307\tvalid's binary_logloss: 0.477436\n",
      "[200]\ttrain's binary_logloss: 1.8951e-05\tvalid's binary_logloss: 0.407716\n",
      "[250]\ttrain's binary_logloss: 3.7517e-06\tvalid's binary_logloss: 0.34489\n",
      "[300]\ttrain's binary_logloss: 1.2996e-06\tvalid's binary_logloss: 0.3244\n",
      "[350]\ttrain's binary_logloss: 7.01789e-07\tvalid's binary_logloss: 0.320183\n",
      "[400]\ttrain's binary_logloss: 4.84757e-07\tvalid's binary_logloss: 0.312785\n",
      "[450]\ttrain's binary_logloss: 4.07381e-07\tvalid's binary_logloss: 0.319694\n",
      "[500]\ttrain's binary_logloss: 3.64842e-07\tvalid's binary_logloss: 0.319249\n",
      "Early stopping, best iteration is:\n",
      "[408]\ttrain's binary_logloss: 4.62779e-07\tvalid's binary_logloss: 0.310544\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting': 'gbdt',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'bagging_freq': 1,\n",
    "    'pos_bagging_fraction': 0.9,\n",
    "    'neg_bagging_fraction': 0.2,\n",
    "}\n",
    "\n",
    "lgb_smoteenn = lgb.train(params,\n",
    "                         D_trn,\n",
    "                         valid_sets=[D_trn, D_val],\n",
    "                         valid_names=['train', 'valid'],\n",
    "                         num_boost_round=1000,\n",
    "                         early_stopping_rounds=100,\n",
    "                         verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "\n",
    "X_smotetomek, y_smotetomek = smote_tomek.fit_resample(X_trn, y_trn)\n",
    "\n",
    "print(X_smotetomek.shape, y_smotetomek.shape)\n",
    "print(y_smotetomek.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "def plot_loss(epoches, train_losses, valid_losses):\n",
    "    rcParams['figure.figsize'] = (16, 6)\n",
    "    \n",
    "    plt.plot(epoches, train_losses, 'g', marker='o', label='train loss')\n",
    "    plt.plot(epoches, valid_losses, 'r', marker='o', label='valid loss')\n",
    "    plt.grid(True, 'both', linestyle='--')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dumm = pd.get_dummies(X, columns=cate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23814, 877)\n"
     ]
    }
   ],
   "source": [
    "print(X_dumm.shape)\n",
    "# print(X_dumm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19051, 877) (19051,)\n",
      "(4763, 877) (4763,)\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(X_dumm, y, test_size=0.2)\n",
    "\n",
    "print(X_trn.shape, y_trn.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "class MoADataset(Dataset):\n",
    "    def __init__(self, dtype, features, targets=None, feature_columns=None):\n",
    "        self.dtype = dtype\n",
    "\n",
    "        if isinstance(features, (pd.DataFrame, pd.Series)):\n",
    "            if feature_columns is not None:\n",
    "                features = features[feature_columns]\n",
    "            features = features.values\n",
    "        self.features = torch.tensor(features, dtype=self.dtype)\n",
    "        self.feature_columns = feature_columns\n",
    "\n",
    "        if targets is None:\n",
    "            targets = -np.ones(self.features.shape[0])  # фиктивный таргет, если идет инференс модели\n",
    "        elif isinstance(targets, (pd.DataFrame, pd.Series)):\n",
    "            targets = targets.values\n",
    "        self.targets = torch.tensor(targets, dtype=self.dtype)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.features[i], self.targets[i]\n",
    "#         return {\n",
    "#             'x': self.features[i],\n",
    "#             'y': self.targets[i]\n",
    "#         }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19051, 1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_trn).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MoADataset(dtype, X_trn, pd.DataFrame(y_trn))\n",
    "valid_dataset = MoADataset(dtype, X_val, pd.DataFrame(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2 ** 8\n",
    "# num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoAModel(nn.Module):\n",
    "    def __init__(self, dtype, num_in_features, num_out_featuers, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_in_features),\n",
    "            \n",
    "            nn.Linear(num_in_features, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(400, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(100, num_out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(model, train_dataloader, valid_dataloader):\n",
    "    running_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    train_loss = running_loss / cnt\n",
    "\n",
    "    running_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i, data in enumerate(valid_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    valid_loss = running_loss / cnt\n",
    "    \n",
    "    return train_loss, valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.423\n",
      "[1,    20] loss: 0.235\n",
      "[1,    30] loss: 0.142\n",
      "[1,    40] loss: 0.104\n",
      "[1,    50] loss: 0.082\n",
      "[1,    60] loss: 0.068\n",
      "[1,    70] loss: 0.059\n",
      "train_loss = 0.052502, valid_loss = 0.057065\n",
      "\n",
      "[2,    10] loss: 0.047\n",
      "[2,    20] loss: 0.047\n",
      "[2,    30] loss: 0.042\n",
      "[2,    40] loss: 0.032\n",
      "[2,    50] loss: 0.039\n",
      "[2,    60] loss: 0.044\n",
      "[2,    70] loss: 0.038\n",
      "train_loss = 0.035846, valid_loss = 0.045871\n",
      "\n",
      "[3,    10] loss: 0.037\n",
      "[3,    20] loss: 0.036\n",
      "[3,    30] loss: 0.037\n",
      "[3,    40] loss: 0.037\n",
      "[3,    50] loss: 0.028\n",
      "[3,    60] loss: 0.031\n",
      "[3,    70] loss: 0.023\n",
      "train_loss = 0.028035, valid_loss = 0.041196\n",
      "\n",
      "[4,    10] loss: 0.028\n",
      "[4,    20] loss: 0.033\n",
      "[4,    30] loss: 0.036\n",
      "[4,    40] loss: 0.029\n",
      "[4,    50] loss: 0.029\n",
      "[4,    60] loss: 0.032\n",
      "[4,    70] loss: 0.029\n",
      "train_loss = 0.024356, valid_loss = 0.040499\n",
      "\n",
      "[5,    10] loss: 0.022\n",
      "[5,    20] loss: 0.022\n",
      "[5,    30] loss: 0.022\n",
      "[5,    40] loss: 0.022\n",
      "[5,    50] loss: 0.029\n",
      "[5,    60] loss: 0.024\n",
      "[5,    70] loss: 0.025\n",
      "train_loss = 0.018339, valid_loss = 0.043403\n",
      "\n",
      "[6,    10] loss: 0.024\n",
      "[6,    20] loss: 0.020\n",
      "[6,    30] loss: 0.021\n",
      "[6,    40] loss: 0.023\n",
      "[6,    50] loss: 0.026\n",
      "[6,    60] loss: 0.016\n",
      "[6,    70] loss: 0.015\n",
      "train_loss = 0.015836, valid_loss = 0.042235\n",
      "\n",
      "[7,    10] loss: 0.024\n",
      "[7,    20] loss: 0.012\n",
      "[7,    30] loss: 0.016\n",
      "[7,    40] loss: 0.015\n",
      "[7,    50] loss: 0.019\n",
      "[7,    60] loss: 0.018\n",
      "[7,    70] loss: 0.020\n",
      "train_loss = 0.014028, valid_loss = 0.042835\n",
      "\n",
      "[8,    10] loss: 0.015\n",
      "[8,    20] loss: 0.020\n",
      "[8,    30] loss: 0.017\n",
      "[8,    40] loss: 0.011\n",
      "[8,    50] loss: 0.021\n",
      "[8,    60] loss: 0.010\n",
      "[8,    70] loss: 0.017\n",
      "train_loss = 0.013365, valid_loss = 0.045885\n",
      "\n",
      "[9,    10] loss: 0.012\n",
      "[9,    20] loss: 0.014\n",
      "[9,    30] loss: 0.012\n",
      "[9,    40] loss: 0.014\n",
      "[9,    50] loss: 0.012\n",
      "[9,    60] loss: 0.014\n",
      "[9,    70] loss: 0.016\n",
      "train_loss = 0.011342, valid_loss = 0.047367\n",
      "\n",
      "[10,    10] loss: 0.012\n",
      "[10,    20] loss: 0.011\n",
      "[10,    30] loss: 0.017\n",
      "[10,    40] loss: 0.015\n",
      "[10,    50] loss: 0.020\n",
      "[10,    60] loss: 0.010\n",
      "[10,    70] loss: 0.010\n",
      "train_loss = 0.009449, valid_loss = 0.047115\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel(dtype, num_in_features, num_out_features)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 more epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.718\n",
      "[1,    20] loss: 0.550\n",
      "[1,    30] loss: 0.428\n",
      "[1,    40] loss: 0.330\n",
      "[1,    50] loss: 0.268\n",
      "[1,    60] loss: 0.209\n",
      "[1,    70] loss: 0.177\n",
      "train_loss = 0.146991, valid_loss = 0.150431\n",
      "\n",
      "[2,    10] loss: 0.139\n",
      "[2,    20] loss: 0.127\n",
      "[2,    30] loss: 0.113\n",
      "[2,    40] loss: 0.092\n",
      "[2,    50] loss: 0.089\n",
      "[2,    60] loss: 0.077\n",
      "[2,    70] loss: 0.074\n",
      "train_loss = 0.066016, valid_loss = 0.067801\n",
      "\n",
      "[3,    10] loss: 0.064\n",
      "[3,    20] loss: 0.066\n",
      "[3,    30] loss: 0.053\n",
      "[3,    40] loss: 0.067\n",
      "[3,    50] loss: 0.041\n",
      "[3,    60] loss: 0.051\n",
      "[3,    70] loss: 0.046\n",
      "train_loss = 0.045224, valid_loss = 0.049422\n",
      "\n",
      "[4,    10] loss: 0.041\n",
      "[4,    20] loss: 0.048\n",
      "[4,    30] loss: 0.037\n",
      "[4,    40] loss: 0.042\n",
      "[4,    50] loss: 0.044\n",
      "[4,    60] loss: 0.040\n",
      "[4,    70] loss: 0.039\n",
      "train_loss = 0.039855, valid_loss = 0.046561\n",
      "\n",
      "[5,    10] loss: 0.039\n",
      "[5,    20] loss: 0.042\n",
      "[5,    30] loss: 0.036\n",
      "[5,    40] loss: 0.035\n",
      "[5,    50] loss: 0.030\n",
      "[5,    60] loss: 0.038\n",
      "[5,    70] loss: 0.035\n",
      "train_loss = 0.033467, valid_loss = 0.043613\n",
      "\n",
      "[6,    10] loss: 0.036\n",
      "[6,    20] loss: 0.026\n",
      "[6,    30] loss: 0.030\n",
      "[6,    40] loss: 0.032\n",
      "[6,    50] loss: 0.045\n",
      "[6,    60] loss: 0.025\n",
      "[6,    70] loss: 0.038\n",
      "train_loss = 0.029156, valid_loss = 0.044847\n",
      "\n",
      "[7,    10] loss: 0.033\n",
      "[7,    20] loss: 0.020\n",
      "[7,    30] loss: 0.035\n",
      "[7,    40] loss: 0.031\n",
      "[7,    50] loss: 0.037\n",
      "[7,    60] loss: 0.031\n",
      "[7,    70] loss: 0.030\n",
      "train_loss = 0.027467, valid_loss = 0.042231\n",
      "\n",
      "[8,    10] loss: 0.027\n",
      "[8,    20] loss: 0.029\n",
      "[8,    30] loss: 0.024\n",
      "[8,    40] loss: 0.031\n",
      "[8,    50] loss: 0.023\n",
      "[8,    60] loss: 0.019\n",
      "[8,    70] loss: 0.025\n",
      "train_loss = 0.025902, valid_loss = 0.042721\n",
      "\n",
      "[9,    10] loss: 0.023\n",
      "[9,    20] loss: 0.028\n",
      "[9,    30] loss: 0.028\n",
      "[9,    40] loss: 0.022\n",
      "[9,    50] loss: 0.018\n",
      "[9,    60] loss: 0.022\n",
      "[9,    70] loss: 0.021\n",
      "train_loss = 0.020005, valid_loss = 0.041969\n",
      "\n",
      "[10,    10] loss: 0.023\n",
      "[10,    20] loss: 0.016\n",
      "[10,    30] loss: 0.020\n",
      "[10,    40] loss: 0.031\n",
      "[10,    50] loss: 0.017\n",
      "[10,    60] loss: 0.018\n",
      "[10,    70] loss: 0.020\n",
      "train_loss = 0.020718, valid_loss = 0.042859\n",
      "\n",
      "[11,    10] loss: 0.015\n",
      "[11,    20] loss: 0.016\n",
      "[11,    30] loss: 0.015\n",
      "[11,    40] loss: 0.020\n",
      "[11,    50] loss: 0.019\n",
      "[11,    60] loss: 0.021\n",
      "[11,    70] loss: 0.023\n",
      "train_loss = 0.017265, valid_loss = 0.039729\n",
      "\n",
      "[12,    10] loss: 0.025\n",
      "[12,    20] loss: 0.015\n",
      "[12,    30] loss: 0.024\n",
      "[12,    40] loss: 0.017\n",
      "[12,    50] loss: 0.020\n",
      "[12,    60] loss: 0.019\n",
      "[12,    70] loss: 0.017\n",
      "train_loss = 0.014194, valid_loss = 0.042252\n",
      "\n",
      "[13,    10] loss: 0.019\n",
      "[13,    20] loss: 0.015\n",
      "[13,    30] loss: 0.014\n",
      "[13,    40] loss: 0.015\n",
      "[13,    50] loss: 0.014\n",
      "[13,    60] loss: 0.016\n",
      "[13,    70] loss: 0.016\n",
      "train_loss = 0.011568, valid_loss = 0.043435\n",
      "\n",
      "[14,    10] loss: 0.013\n",
      "[14,    20] loss: 0.014\n",
      "[14,    30] loss: 0.013\n",
      "[14,    40] loss: 0.016\n",
      "[14,    50] loss: 0.014\n",
      "[14,    60] loss: 0.013\n",
      "[14,    70] loss: 0.019\n",
      "train_loss = 0.012400, valid_loss = 0.046523\n",
      "\n",
      "[15,    10] loss: 0.010\n",
      "[15,    20] loss: 0.012\n",
      "[15,    30] loss: 0.007\n",
      "[15,    40] loss: 0.009\n",
      "[15,    50] loss: 0.014\n",
      "[15,    60] loss: 0.012\n",
      "[15,    70] loss: 0.013\n",
      "train_loss = 0.011225, valid_loss = 0.047865\n",
      "\n",
      "[16,    10] loss: 0.010\n",
      "[16,    20] loss: 0.010\n",
      "[16,    30] loss: 0.016\n",
      "[16,    40] loss: 0.011\n",
      "[16,    50] loss: 0.019\n",
      "[16,    60] loss: 0.014\n",
      "[16,    70] loss: 0.010\n",
      "train_loss = 0.011117, valid_loss = 0.046804\n",
      "\n",
      "[17,    10] loss: 0.008\n",
      "[17,    20] loss: 0.008\n",
      "[17,    30] loss: 0.011\n",
      "[17,    40] loss: 0.013\n",
      "[17,    50] loss: 0.010\n",
      "[17,    60] loss: 0.008\n",
      "[17,    70] loss: 0.007\n",
      "train_loss = 0.009284, valid_loss = 0.048001\n",
      "\n",
      "[18,    10] loss: 0.012\n",
      "[18,    20] loss: 0.011\n",
      "[18,    30] loss: 0.011\n",
      "[18,    40] loss: 0.011\n",
      "[18,    50] loss: 0.009\n",
      "[18,    60] loss: 0.011\n",
      "[18,    70] loss: 0.004\n",
      "train_loss = 0.007476, valid_loss = 0.051473\n",
      "\n",
      "[19,    10] loss: 0.006\n",
      "[19,    20] loss: 0.005\n",
      "[19,    30] loss: 0.007\n",
      "[19,    40] loss: 0.009\n",
      "[19,    50] loss: 0.011\n",
      "[19,    60] loss: 0.009\n",
      "[19,    70] loss: 0.009\n",
      "train_loss = 0.006957, valid_loss = 0.051544\n",
      "\n",
      "[20,    10] loss: 0.004\n",
      "[20,    20] loss: 0.004\n",
      "[20,    30] loss: 0.007\n",
      "[20,    40] loss: 0.006\n",
      "[20,    50] loss: 0.005\n",
      "[20,    60] loss: 0.009\n",
      "[20,    70] loss: 0.014\n",
      "train_loss = 0.006858, valid_loss = 0.050675\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel(dtype, num_in_features, num_out_features)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel(dtype, num_in_features, num_out_features, dropout_rate=0.1)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "epoches = [i for i in range(30)]\n",
    "\n",
    "for epoch in epoches:  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(epoches, train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoAModel2(nn.Module):\n",
    "    def __init__(self, dtype, num_in_features, num_out_featuers, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.net = nn.Sequential(\n",
    "#             nn.BatchNorm1d(num_in_features),\n",
    "            \n",
    "            nn.Linear(num_in_features, 400),\n",
    "#             nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(400, 200),\n",
    "#             nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "#             nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(100, num_out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.337\n",
      "[1,    20] loss: 0.088\n",
      "[1,    30] loss: 0.093\n",
      "[1,    40] loss: 0.075\n",
      "[1,    50] loss: 0.048\n",
      "[1,    60] loss: 0.052\n",
      "[1,    70] loss: 0.061\n",
      "train_loss = 0.044542, valid_loss = 0.052863\n",
      "\n",
      "[2,    10] loss: 0.048\n",
      "[2,    20] loss: 0.041\n",
      "[2,    30] loss: 0.028\n",
      "[2,    40] loss: 0.047\n",
      "[2,    50] loss: 0.049\n",
      "[2,    60] loss: 0.039\n",
      "[2,    70] loss: 0.033\n",
      "train_loss = 0.035462, valid_loss = 0.049025\n",
      "\n",
      "[3,    10] loss: 0.041\n",
      "[3,    20] loss: 0.040\n",
      "[3,    30] loss: 0.037\n",
      "[3,    40] loss: 0.028\n",
      "[3,    50] loss: 0.033\n",
      "[3,    60] loss: 0.032\n",
      "[3,    70] loss: 0.026\n",
      "train_loss = 0.029317, valid_loss = 0.045471\n",
      "\n",
      "[4,    10] loss: 0.031\n",
      "[4,    20] loss: 0.026\n",
      "[4,    30] loss: 0.024\n",
      "[4,    40] loss: 0.032\n",
      "[4,    50] loss: 0.022\n",
      "[4,    60] loss: 0.028\n",
      "[4,    70] loss: 0.027\n",
      "train_loss = 0.025400, valid_loss = 0.046043\n",
      "\n",
      "[5,    10] loss: 0.034\n",
      "[5,    20] loss: 0.028\n",
      "[5,    30] loss: 0.024\n",
      "[5,    40] loss: 0.024\n",
      "[5,    50] loss: 0.029\n",
      "[5,    60] loss: 0.024\n",
      "[5,    70] loss: 0.030\n",
      "train_loss = 0.020545, valid_loss = 0.047440\n",
      "\n",
      "[6,    10] loss: 0.020\n",
      "[6,    20] loss: 0.028\n",
      "[6,    30] loss: 0.019\n",
      "[6,    40] loss: 0.021\n",
      "[6,    50] loss: 0.034\n",
      "[6,    60] loss: 0.017\n",
      "[6,    70] loss: 0.015\n",
      "train_loss = 0.016769, valid_loss = 0.055549\n",
      "\n",
      "[7,    10] loss: 0.021\n",
      "[7,    20] loss: 0.018\n",
      "[7,    30] loss: 0.021\n",
      "[7,    40] loss: 0.022\n",
      "[7,    50] loss: 0.025\n",
      "[7,    60] loss: 0.023\n",
      "[7,    70] loss: 0.021\n",
      "train_loss = 0.016834, valid_loss = 0.057376\n",
      "\n",
      "[8,    10] loss: 0.012\n",
      "[8,    20] loss: 0.027\n",
      "[8,    30] loss: 0.014\n",
      "[8,    40] loss: 0.013\n",
      "[8,    50] loss: 0.017\n",
      "[8,    60] loss: 0.021\n",
      "[8,    70] loss: 0.022\n",
      "train_loss = 0.012324, valid_loss = 0.055285\n",
      "\n",
      "[9,    10] loss: 0.013\n",
      "[9,    20] loss: 0.015\n",
      "[9,    30] loss: 0.026\n",
      "[9,    40] loss: 0.013\n",
      "[9,    50] loss: 0.021\n",
      "[9,    60] loss: 0.013\n",
      "[9,    70] loss: 0.014\n",
      "train_loss = 0.012606, valid_loss = 0.067769\n",
      "\n",
      "[10,    10] loss: 0.011\n",
      "[10,    20] loss: 0.019\n",
      "[10,    30] loss: 0.013\n",
      "[10,    40] loss: 0.007\n",
      "[10,    50] loss: 0.012\n",
      "[10,    60] loss: 0.017\n",
      "[10,    70] loss: 0.009\n",
      "train_loss = 0.013885, valid_loss = 0.081280\n",
      "\n",
      "[11,    10] loss: 0.013\n",
      "[11,    20] loss: 0.011\n",
      "[11,    30] loss: 0.013\n",
      "[11,    40] loss: 0.009\n",
      "[11,    50] loss: 0.013\n",
      "[11,    60] loss: 0.012\n",
      "[11,    70] loss: 0.008\n",
      "train_loss = 0.008787, valid_loss = 0.101919\n",
      "\n",
      "[12,    10] loss: 0.014\n",
      "[12,    20] loss: 0.006\n",
      "[12,    30] loss: 0.010\n",
      "[12,    40] loss: 0.007\n",
      "[12,    50] loss: 0.007\n",
      "[12,    60] loss: 0.016\n",
      "[12,    70] loss: 0.012\n",
      "train_loss = 0.009182, valid_loss = 0.089915\n",
      "\n",
      "[13,    10] loss: 0.013\n",
      "[13,    20] loss: 0.009\n",
      "[13,    30] loss: 0.009\n",
      "[13,    40] loss: 0.012\n",
      "[13,    50] loss: 0.008\n",
      "[13,    60] loss: 0.007\n",
      "[13,    70] loss: 0.005\n",
      "train_loss = 0.007651, valid_loss = 0.107707\n",
      "\n",
      "[14,    10] loss: 0.013\n",
      "[14,    20] loss: 0.003\n",
      "[14,    30] loss: 0.007\n",
      "[14,    40] loss: 0.003\n",
      "[14,    50] loss: 0.012\n",
      "[14,    60] loss: 0.005\n",
      "[14,    70] loss: 0.014\n",
      "train_loss = 0.006886, valid_loss = 0.124381\n",
      "\n",
      "[15,    10] loss: 0.007\n",
      "[15,    20] loss: 0.009\n",
      "[15,    30] loss: 0.015\n",
      "[15,    40] loss: 0.012\n",
      "[15,    50] loss: 0.011\n",
      "[15,    60] loss: 0.025\n",
      "[15,    70] loss: 0.008\n",
      "train_loss = 0.007976, valid_loss = 0.088365\n",
      "\n",
      "[16,    10] loss: 0.011\n",
      "[16,    20] loss: 0.004\n",
      "[16,    30] loss: 0.010\n",
      "[16,    40] loss: 0.003\n",
      "[16,    50] loss: 0.004\n",
      "[16,    60] loss: 0.010\n",
      "[16,    70] loss: 0.006\n",
      "train_loss = 0.007988, valid_loss = 0.112012\n",
      "\n",
      "[17,    10] loss: 0.004\n",
      "[17,    20] loss: 0.011\n",
      "[17,    30] loss: 0.006\n",
      "[17,    40] loss: 0.009\n",
      "[17,    50] loss: 0.008\n",
      "[17,    60] loss: 0.007\n",
      "[17,    70] loss: 0.003\n",
      "train_loss = 0.004493, valid_loss = 0.095450\n",
      "\n",
      "[18,    10] loss: 0.003\n",
      "[18,    20] loss: 0.005\n",
      "[18,    30] loss: 0.004\n",
      "[18,    40] loss: 0.009\n",
      "[18,    50] loss: 0.007\n",
      "[18,    60] loss: 0.006\n",
      "[18,    70] loss: 0.002\n",
      "train_loss = 0.005104, valid_loss = 0.125615\n",
      "\n",
      "[19,    10] loss: 0.004\n",
      "[19,    20] loss: 0.002\n",
      "[19,    30] loss: 0.005\n",
      "[19,    40] loss: 0.005\n",
      "[19,    50] loss: 0.004\n",
      "[19,    60] loss: 0.006\n",
      "[19,    70] loss: 0.006\n",
      "train_loss = 0.005505, valid_loss = 0.131378\n",
      "\n",
      "[20,    10] loss: 0.006\n",
      "[20,    20] loss: 0.007\n",
      "[20,    30] loss: 0.001\n",
      "[20,    40] loss: 0.007\n",
      "[20,    50] loss: 0.002\n",
      "[20,    60] loss: 0.003\n",
      "[20,    70] loss: 0.003\n",
      "train_loss = 0.003075, valid_loss = 0.163812\n",
      "\n",
      "[21,    10] loss: 0.004\n",
      "[21,    20] loss: 0.001\n",
      "[21,    30] loss: 0.007\n",
      "[21,    40] loss: 0.011\n",
      "[21,    50] loss: 0.012\n",
      "[21,    60] loss: 0.014\n",
      "[21,    70] loss: 0.008\n",
      "train_loss = 0.007146, valid_loss = 0.124793\n",
      "\n",
      "[22,    10] loss: 0.007\n",
      "[22,    20] loss: 0.007\n",
      "[22,    30] loss: 0.002\n",
      "[22,    40] loss: 0.009\n",
      "[22,    50] loss: 0.006\n",
      "[22,    60] loss: 0.007\n",
      "[22,    70] loss: 0.005\n",
      "train_loss = 0.004418, valid_loss = 0.128372\n",
      "\n",
      "[23,    10] loss: 0.003\n",
      "[23,    20] loss: 0.006\n",
      "[23,    30] loss: 0.004\n",
      "[23,    40] loss: 0.002\n",
      "[23,    50] loss: 0.004\n",
      "[23,    60] loss: 0.005\n",
      "[23,    70] loss: 0.003\n",
      "train_loss = 0.004158, valid_loss = 0.132892\n",
      "\n",
      "[24,    10] loss: 0.002\n",
      "[24,    20] loss: 0.004\n",
      "[24,    30] loss: 0.006\n",
      "[24,    40] loss: 0.009\n",
      "[24,    50] loss: 0.005\n",
      "[24,    60] loss: 0.002\n",
      "[24,    70] loss: 0.002\n",
      "train_loss = 0.003369, valid_loss = 0.139060\n",
      "\n",
      "[25,    10] loss: 0.002\n",
      "[25,    20] loss: 0.007\n",
      "[25,    30] loss: 0.002\n",
      "[25,    40] loss: 0.005\n",
      "[25,    50] loss: 0.012\n",
      "[25,    60] loss: 0.003\n",
      "[25,    70] loss: 0.003\n",
      "train_loss = 0.004483, valid_loss = 0.123118\n",
      "\n",
      "[26,    10] loss: 0.002\n",
      "[26,    20] loss: 0.003\n",
      "[26,    30] loss: 0.013\n",
      "[26,    40] loss: 0.004\n",
      "[26,    50] loss: 0.002\n",
      "[26,    60] loss: 0.006\n",
      "[26,    70] loss: 0.004\n",
      "train_loss = 0.006323, valid_loss = 0.108726\n",
      "\n",
      "[27,    10] loss: 0.005\n",
      "[27,    20] loss: 0.004\n",
      "[27,    30] loss: 0.011\n",
      "[27,    40] loss: 0.003\n",
      "[27,    50] loss: 0.004\n",
      "[27,    60] loss: 0.001\n",
      "[27,    70] loss: 0.001\n",
      "train_loss = 0.003064, valid_loss = 0.121044\n",
      "\n",
      "[28,    10] loss: 0.002\n",
      "[28,    20] loss: 0.001\n",
      "[28,    30] loss: 0.007\n",
      "[28,    40] loss: 0.007\n",
      "[28,    50] loss: 0.002\n",
      "[28,    60] loss: 0.003\n",
      "[28,    70] loss: 0.002\n",
      "train_loss = 0.002565, valid_loss = 0.131798\n",
      "\n",
      "[29,    10] loss: 0.001\n",
      "[29,    20] loss: 0.004\n",
      "[29,    30] loss: 0.002\n",
      "[29,    40] loss: 0.002\n",
      "[29,    50] loss: 0.005\n",
      "[29,    60] loss: 0.001\n",
      "[29,    70] loss: 0.004\n",
      "train_loss = 0.013994, valid_loss = 0.157726\n",
      "\n",
      "[30,    10] loss: 0.006\n",
      "[30,    20] loss: 0.007\n",
      "[30,    30] loss: 0.010\n",
      "[30,    40] loss: 0.009\n",
      "[30,    50] loss: 0.009\n",
      "[30,    60] loss: 0.004\n",
      "[30,    70] loss: 0.002\n",
      "train_loss = 0.005357, valid_loss = 0.110073\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel2(dtype, num_in_features, num_out_features)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 deeper net 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoAModel2(nn.Module):\n",
    "    def __init__(self, dtype, num_in_features, num_out_featuers, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_in_features),\n",
    "            \n",
    "            nn.Linear(num_in_features, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(400, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(100, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(50, 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(20, num_out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.730\n",
      "[1,    20] loss: 0.672\n",
      "[1,    30] loss: 0.613\n",
      "[1,    40] loss: 0.604\n",
      "[1,    50] loss: 0.552\n",
      "[1,    60] loss: 0.520\n",
      "[1,    70] loss: 0.482\n",
      "train_loss = 0.453528, valid_loss = 0.448035\n",
      "\n",
      "[2,    10] loss: 0.437\n",
      "[2,    20] loss: 0.410\n",
      "[2,    30] loss: 0.381\n",
      "[2,    40] loss: 0.364\n",
      "[2,    50] loss: 0.338\n",
      "[2,    60] loss: 0.307\n",
      "[2,    70] loss: 0.284\n",
      "train_loss = 0.269983, valid_loss = 0.274550\n",
      "\n",
      "[3,    10] loss: 0.266\n",
      "[3,    20] loss: 0.254\n",
      "[3,    30] loss: 0.235\n",
      "[3,    40] loss: 0.219\n",
      "[3,    50] loss: 0.203\n",
      "[3,    60] loss: 0.192\n",
      "[3,    70] loss: 0.184\n",
      "train_loss = 0.173501, valid_loss = 0.171607\n",
      "\n",
      "[4,    10] loss: 0.163\n",
      "[4,    20] loss: 0.163\n",
      "[4,    30] loss: 0.150\n",
      "[4,    40] loss: 0.149\n",
      "[4,    50] loss: 0.141\n",
      "[4,    60] loss: 0.132\n",
      "[4,    70] loss: 0.132\n",
      "train_loss = 0.119703, valid_loss = 0.126797\n",
      "\n",
      "[5,    10] loss: 0.118\n",
      "[5,    20] loss: 0.115\n",
      "[5,    30] loss: 0.110\n",
      "[5,    40] loss: 0.111\n",
      "[5,    50] loss: 0.107\n",
      "[5,    60] loss: 0.096\n",
      "[5,    70] loss: 0.092\n",
      "train_loss = 0.094674, valid_loss = 0.098280\n",
      "\n",
      "[6,    10] loss: 0.093\n",
      "[6,    20] loss: 0.076\n",
      "[6,    30] loss: 0.092\n",
      "[6,    40] loss: 0.091\n",
      "[6,    50] loss: 0.083\n",
      "[6,    60] loss: 0.083\n",
      "[6,    70] loss: 0.075\n",
      "train_loss = 0.076471, valid_loss = 0.082891\n",
      "\n",
      "[7,    10] loss: 0.081\n",
      "[7,    20] loss: 0.070\n",
      "[7,    30] loss: 0.075\n",
      "[7,    40] loss: 0.067\n",
      "[7,    50] loss: 0.075\n",
      "[7,    60] loss: 0.078\n",
      "[7,    70] loss: 0.077\n",
      "train_loss = 0.069093, valid_loss = 0.074758\n",
      "\n",
      "[8,    10] loss: 0.073\n",
      "[8,    20] loss: 0.066\n",
      "[8,    30] loss: 0.066\n",
      "[8,    40] loss: 0.069\n",
      "[8,    50] loss: 0.055\n",
      "[8,    60] loss: 0.058\n",
      "[8,    70] loss: 0.066\n",
      "train_loss = 0.062811, valid_loss = 0.067070\n",
      "\n",
      "[9,    10] loss: 0.066\n",
      "[9,    20] loss: 0.060\n",
      "[9,    30] loss: 0.057\n",
      "[9,    40] loss: 0.065\n",
      "[9,    50] loss: 0.047\n",
      "[9,    60] loss: 0.064\n",
      "[9,    70] loss: 0.057\n",
      "train_loss = 0.055321, valid_loss = 0.064323\n",
      "\n",
      "[10,    10] loss: 0.059\n",
      "[10,    20] loss: 0.061\n",
      "[10,    30] loss: 0.053\n",
      "[10,    40] loss: 0.069\n",
      "[10,    50] loss: 0.056\n",
      "[10,    60] loss: 0.056\n",
      "[10,    70] loss: 0.057\n",
      "train_loss = 0.054014, valid_loss = 0.063872\n",
      "\n",
      "[11,    10] loss: 0.055\n",
      "[11,    20] loss: 0.055\n",
      "[11,    30] loss: 0.049\n",
      "[11,    40] loss: 0.061\n",
      "[11,    50] loss: 0.047\n",
      "[11,    60] loss: 0.069\n",
      "[11,    70] loss: 0.040\n",
      "train_loss = 0.051974, valid_loss = 0.061966\n",
      "\n",
      "[12,    10] loss: 0.062\n",
      "[12,    20] loss: 0.041\n",
      "[12,    30] loss: 0.043\n",
      "[12,    40] loss: 0.069\n",
      "[12,    50] loss: 0.048\n",
      "[12,    60] loss: 0.054\n",
      "[12,    70] loss: 0.050\n",
      "train_loss = 0.050008, valid_loss = 0.053473\n",
      "\n",
      "[13,    10] loss: 0.040\n",
      "[13,    20] loss: 0.050\n",
      "[13,    30] loss: 0.050\n",
      "[13,    40] loss: 0.050\n",
      "[13,    50] loss: 0.071\n",
      "[13,    60] loss: 0.056\n",
      "[13,    70] loss: 0.039\n",
      "train_loss = 0.049021, valid_loss = 0.054716\n",
      "\n",
      "[14,    10] loss: 0.044\n",
      "[14,    20] loss: 0.054\n",
      "[14,    30] loss: 0.040\n",
      "[14,    40] loss: 0.055\n",
      "[14,    50] loss: 0.062\n",
      "[14,    60] loss: 0.053\n",
      "[14,    70] loss: 0.045\n",
      "train_loss = 0.049423, valid_loss = 0.056775\n",
      "\n",
      "[15,    10] loss: 0.049\n",
      "[15,    20] loss: 0.049\n",
      "[15,    30] loss: 0.044\n",
      "[15,    40] loss: 0.039\n",
      "[15,    50] loss: 0.038\n",
      "[15,    60] loss: 0.043\n",
      "[15,    70] loss: 0.059\n",
      "train_loss = 0.045536, valid_loss = 0.050869\n",
      "\n",
      "[16,    10] loss: 0.047\n",
      "[16,    20] loss: 0.044\n",
      "[16,    30] loss: 0.047\n",
      "[16,    40] loss: 0.041\n",
      "[16,    50] loss: 0.041\n",
      "[16,    60] loss: 0.045\n",
      "[16,    70] loss: 0.039\n",
      "train_loss = 0.041017, valid_loss = 0.052606\n",
      "\n",
      "[17,    10] loss: 0.039\n",
      "[17,    20] loss: 0.042\n",
      "[17,    30] loss: 0.048\n",
      "[17,    40] loss: 0.043\n",
      "[17,    50] loss: 0.035\n",
      "[17,    60] loss: 0.042\n",
      "[17,    70] loss: 0.052\n",
      "train_loss = 0.041593, valid_loss = 0.053204\n",
      "\n",
      "[18,    10] loss: 0.046\n",
      "[18,    20] loss: 0.056\n",
      "[18,    30] loss: 0.035\n",
      "[18,    40] loss: 0.033\n",
      "[18,    50] loss: 0.059\n",
      "[18,    60] loss: 0.034\n",
      "[18,    70] loss: 0.038\n",
      "train_loss = 0.040898, valid_loss = 0.052031\n",
      "\n",
      "[19,    10] loss: 0.031\n",
      "[19,    20] loss: 0.036\n",
      "[19,    30] loss: 0.050\n",
      "[19,    40] loss: 0.044\n",
      "[19,    50] loss: 0.041\n",
      "[19,    60] loss: 0.043\n",
      "[19,    70] loss: 0.036\n",
      "train_loss = 0.037773, valid_loss = 0.050984\n",
      "\n",
      "[20,    10] loss: 0.038\n",
      "[20,    20] loss: 0.056\n",
      "[20,    30] loss: 0.037\n",
      "[20,    40] loss: 0.040\n",
      "[20,    50] loss: 0.038\n",
      "[20,    60] loss: 0.033\n",
      "[20,    70] loss: 0.031\n",
      "train_loss = 0.034312, valid_loss = 0.051953\n",
      "\n",
      "[21,    10] loss: 0.041\n",
      "[21,    20] loss: 0.028\n",
      "[21,    30] loss: 0.043\n",
      "[21,    40] loss: 0.035\n",
      "[21,    50] loss: 0.036\n",
      "[21,    60] loss: 0.033\n",
      "[21,    70] loss: 0.030\n",
      "train_loss = 0.032742, valid_loss = 0.049797\n",
      "\n",
      "[22,    10] loss: 0.032\n",
      "[22,    20] loss: 0.038\n",
      "[22,    30] loss: 0.035\n",
      "[22,    40] loss: 0.029\n",
      "[22,    50] loss: 0.034\n",
      "[22,    60] loss: 0.032\n",
      "[22,    70] loss: 0.030\n",
      "train_loss = 0.030670, valid_loss = 0.048215\n",
      "\n",
      "[23,    10] loss: 0.026\n",
      "[23,    20] loss: 0.039\n",
      "[23,    30] loss: 0.041\n",
      "[23,    40] loss: 0.031\n",
      "[23,    50] loss: 0.029\n",
      "[23,    60] loss: 0.029\n",
      "[23,    70] loss: 0.026\n",
      "train_loss = 0.029903, valid_loss = 0.049787\n",
      "\n",
      "[24,    10] loss: 0.036\n",
      "[24,    20] loss: 0.021\n",
      "[24,    30] loss: 0.030\n",
      "[24,    40] loss: 0.028\n",
      "[24,    50] loss: 0.032\n",
      "[24,    60] loss: 0.042\n",
      "[24,    70] loss: 0.028\n",
      "train_loss = 0.027420, valid_loss = 0.052368\n",
      "\n",
      "[25,    10] loss: 0.036\n",
      "[25,    20] loss: 0.025\n",
      "[25,    30] loss: 0.022\n",
      "[25,    40] loss: 0.031\n",
      "[25,    50] loss: 0.036\n",
      "[25,    60] loss: 0.033\n",
      "[25,    70] loss: 0.015\n",
      "train_loss = 0.029526, valid_loss = 0.052551\n",
      "\n",
      "[26,    10] loss: 0.036\n",
      "[26,    20] loss: 0.031\n",
      "[26,    30] loss: 0.027\n",
      "[26,    40] loss: 0.025\n",
      "[26,    50] loss: 0.020\n",
      "[26,    60] loss: 0.026\n",
      "[26,    70] loss: 0.022\n",
      "train_loss = 0.023372, valid_loss = 0.054445\n",
      "\n",
      "[27,    10] loss: 0.027\n",
      "[27,    20] loss: 0.025\n",
      "[27,    30] loss: 0.024\n",
      "[27,    40] loss: 0.028\n",
      "[27,    50] loss: 0.032\n",
      "[27,    60] loss: 0.029\n",
      "[27,    70] loss: 0.022\n",
      "train_loss = 0.023802, valid_loss = 0.051526\n",
      "\n",
      "[28,    10] loss: 0.019\n",
      "[28,    20] loss: 0.024\n",
      "[28,    30] loss: 0.026\n",
      "[28,    40] loss: 0.025\n",
      "[28,    50] loss: 0.030\n",
      "[28,    60] loss: 0.021\n",
      "[28,    70] loss: 0.041\n",
      "train_loss = 0.023595, valid_loss = 0.053601\n",
      "\n",
      "[29,    10] loss: 0.023\n",
      "[29,    20] loss: 0.026\n",
      "[29,    30] loss: 0.018\n",
      "[29,    40] loss: 0.014\n",
      "[29,    50] loss: 0.016\n",
      "[29,    60] loss: 0.024\n",
      "[29,    70] loss: 0.020\n",
      "train_loss = 0.022581, valid_loss = 0.048821\n",
      "\n",
      "[30,    10] loss: 0.022\n",
      "[30,    20] loss: 0.015\n",
      "[30,    30] loss: 0.031\n",
      "[30,    40] loss: 0.026\n",
      "[30,    50] loss: 0.020\n",
      "[30,    60] loss: 0.023\n",
      "[30,    70] loss: 0.023\n",
      "train_loss = 0.020524, valid_loss = 0.048353\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel2(dtype, num_in_features, num_out_features)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.737\n",
      "[1,    20] loss: 0.653\n",
      "[1,    30] loss: 0.594\n",
      "[1,    40] loss: 0.546\n",
      "[1,    50] loss: 0.511\n",
      "[1,    60] loss: 0.463\n",
      "[1,    70] loss: 0.431\n",
      "train_loss = 0.403217, valid_loss = 0.407900\n",
      "\n",
      "[2,    10] loss: 0.399\n",
      "[2,    20] loss: 0.366\n",
      "[2,    30] loss: 0.344\n",
      "[2,    40] loss: 0.320\n",
      "[2,    50] loss: 0.305\n",
      "[2,    60] loss: 0.281\n",
      "[2,    70] loss: 0.264\n",
      "train_loss = 0.250170, valid_loss = 0.252615\n",
      "\n",
      "[3,    10] loss: 0.243\n",
      "[3,    20] loss: 0.227\n",
      "[3,    30] loss: 0.213\n",
      "[3,    40] loss: 0.197\n",
      "[3,    50] loss: 0.187\n",
      "[3,    60] loss: 0.176\n",
      "[3,    70] loss: 0.168\n",
      "train_loss = 0.154736, valid_loss = 0.158895\n",
      "\n",
      "[4,    10] loss: 0.153\n",
      "[4,    20] loss: 0.147\n",
      "[4,    30] loss: 0.136\n",
      "[4,    40] loss: 0.127\n",
      "[4,    50] loss: 0.116\n",
      "[4,    60] loss: 0.118\n",
      "[4,    70] loss: 0.110\n",
      "train_loss = 0.105255, valid_loss = 0.108573\n",
      "\n",
      "[5,    10] loss: 0.097\n",
      "[5,    20] loss: 0.093\n",
      "[5,    30] loss: 0.094\n",
      "[5,    40] loss: 0.087\n",
      "[5,    50] loss: 0.088\n",
      "[5,    60] loss: 0.082\n",
      "[5,    70] loss: 0.091\n",
      "train_loss = 0.077305, valid_loss = 0.082192\n",
      "\n",
      "[6,    10] loss: 0.073\n",
      "[6,    20] loss: 0.075\n",
      "[6,    30] loss: 0.069\n",
      "[6,    40] loss: 0.070\n",
      "[6,    50] loss: 0.069\n",
      "[6,    60] loss: 0.074\n",
      "[6,    70] loss: 0.068\n",
      "train_loss = 0.060697, valid_loss = 0.067961\n",
      "\n",
      "[7,    10] loss: 0.057\n",
      "[7,    20] loss: 0.062\n",
      "[7,    30] loss: 0.057\n",
      "[7,    40] loss: 0.059\n",
      "[7,    50] loss: 0.048\n",
      "[7,    60] loss: 0.050\n",
      "[7,    70] loss: 0.050\n",
      "train_loss = 0.049199, valid_loss = 0.056252\n",
      "\n",
      "[8,    10] loss: 0.044\n",
      "[8,    20] loss: 0.049\n",
      "[8,    30] loss: 0.045\n",
      "[8,    40] loss: 0.047\n",
      "[8,    50] loss: 0.050\n",
      "[8,    60] loss: 0.051\n",
      "[8,    70] loss: 0.039\n",
      "train_loss = 0.041256, valid_loss = 0.050419\n",
      "\n",
      "[9,    10] loss: 0.037\n",
      "[9,    20] loss: 0.038\n",
      "[9,    30] loss: 0.046\n",
      "[9,    40] loss: 0.035\n",
      "[9,    50] loss: 0.053\n",
      "[9,    60] loss: 0.047\n",
      "[9,    70] loss: 0.044\n",
      "train_loss = 0.035955, valid_loss = 0.047042\n",
      "\n",
      "[10,    10] loss: 0.037\n",
      "[10,    20] loss: 0.029\n",
      "[10,    30] loss: 0.041\n",
      "[10,    40] loss: 0.035\n",
      "[10,    50] loss: 0.038\n",
      "[10,    60] loss: 0.032\n",
      "[10,    70] loss: 0.031\n",
      "train_loss = 0.029340, valid_loss = 0.045855\n",
      "\n",
      "[11,    10] loss: 0.025\n",
      "[11,    20] loss: 0.029\n",
      "[11,    30] loss: 0.029\n",
      "[11,    40] loss: 0.033\n",
      "[11,    50] loss: 0.028\n",
      "[11,    60] loss: 0.027\n",
      "[11,    70] loss: 0.029\n",
      "train_loss = 0.027752, valid_loss = 0.043383\n",
      "\n",
      "[12,    10] loss: 0.021\n",
      "[12,    20] loss: 0.023\n",
      "[12,    30] loss: 0.027\n",
      "[12,    40] loss: 0.028\n",
      "[12,    50] loss: 0.031\n",
      "[12,    60] loss: 0.024\n",
      "[12,    70] loss: 0.020\n",
      "train_loss = 0.020188, valid_loss = 0.041933\n",
      "\n",
      "[13,    10] loss: 0.020\n",
      "[13,    20] loss: 0.022\n",
      "[13,    30] loss: 0.019\n",
      "[13,    40] loss: 0.025\n",
      "[13,    50] loss: 0.016\n",
      "[13,    60] loss: 0.023\n",
      "[13,    70] loss: 0.021\n",
      "train_loss = 0.016950, valid_loss = 0.040314\n",
      "\n",
      "[14,    10] loss: 0.017\n",
      "[14,    20] loss: 0.018\n",
      "[14,    30] loss: 0.016\n",
      "[14,    40] loss: 0.017\n",
      "[14,    50] loss: 0.017\n",
      "[14,    60] loss: 0.019\n",
      "[14,    70] loss: 0.012\n",
      "train_loss = 0.013542, valid_loss = 0.038029\n",
      "\n",
      "[15,    10] loss: 0.026\n",
      "[15,    20] loss: 0.020\n",
      "[15,    30] loss: 0.016\n",
      "[15,    40] loss: 0.014\n",
      "[15,    50] loss: 0.020\n",
      "[15,    60] loss: 0.011\n",
      "[15,    70] loss: 0.018\n",
      "train_loss = 0.010896, valid_loss = 0.038714\n",
      "\n",
      "[16,    10] loss: 0.016\n",
      "[16,    20] loss: 0.009\n",
      "[16,    30] loss: 0.011\n",
      "[16,    40] loss: 0.013\n",
      "[16,    50] loss: 0.018\n",
      "[16,    60] loss: 0.012\n",
      "[16,    70] loss: 0.009\n",
      "train_loss = 0.012565, valid_loss = 0.039926\n",
      "\n",
      "[17,    10] loss: 0.011\n",
      "[17,    20] loss: 0.010\n",
      "[17,    30] loss: 0.016\n",
      "[17,    40] loss: 0.015\n",
      "[17,    50] loss: 0.012\n",
      "[17,    60] loss: 0.010\n",
      "[17,    70] loss: 0.013\n",
      "train_loss = 0.009643, valid_loss = 0.041695\n",
      "\n",
      "[18,    10] loss: 0.010\n",
      "[18,    20] loss: 0.014\n",
      "[18,    30] loss: 0.012\n",
      "[18,    40] loss: 0.011\n",
      "[18,    50] loss: 0.011\n",
      "[18,    60] loss: 0.009\n",
      "[18,    70] loss: 0.009\n",
      "train_loss = 0.008370, valid_loss = 0.044422\n",
      "\n",
      "[19,    10] loss: 0.007\n",
      "[19,    20] loss: 0.011\n",
      "[19,    30] loss: 0.009\n",
      "[19,    40] loss: 0.008\n",
      "[19,    50] loss: 0.008\n",
      "[19,    60] loss: 0.007\n",
      "[19,    70] loss: 0.008\n",
      "train_loss = 0.006887, valid_loss = 0.041430\n",
      "\n",
      "[20,    10] loss: 0.006\n",
      "[20,    20] loss: 0.005\n",
      "[20,    30] loss: 0.008\n",
      "[20,    40] loss: 0.006\n",
      "[20,    50] loss: 0.006\n",
      "[20,    60] loss: 0.011\n",
      "[20,    70] loss: 0.009\n",
      "train_loss = 0.007710, valid_loss = 0.042460\n",
      "\n",
      "[21,    10] loss: 0.006\n",
      "[21,    20] loss: 0.005\n",
      "[21,    30] loss: 0.006\n",
      "[21,    40] loss: 0.009\n",
      "[21,    50] loss: 0.006\n",
      "[21,    60] loss: 0.007\n",
      "[21,    70] loss: 0.011\n",
      "train_loss = 0.005395, valid_loss = 0.041342\n",
      "\n",
      "[22,    10] loss: 0.006\n",
      "[22,    20] loss: 0.005\n",
      "[22,    30] loss: 0.007\n",
      "[22,    40] loss: 0.005\n",
      "[22,    50] loss: 0.005\n",
      "[22,    60] loss: 0.005\n",
      "[22,    70] loss: 0.006\n",
      "train_loss = 0.004821, valid_loss = 0.044401\n",
      "\n",
      "[23,    10] loss: 0.004\n",
      "[23,    20] loss: 0.006\n",
      "[23,    30] loss: 0.004\n",
      "[23,    40] loss: 0.004\n",
      "[23,    50] loss: 0.005\n",
      "[23,    60] loss: 0.003\n",
      "[23,    70] loss: 0.004\n",
      "train_loss = 0.004649, valid_loss = 0.040300\n",
      "\n",
      "[24,    10] loss: 0.003\n",
      "[24,    20] loss: 0.004\n",
      "[24,    30] loss: 0.003\n",
      "[24,    40] loss: 0.003\n",
      "[24,    50] loss: 0.003\n",
      "[24,    60] loss: 0.003\n",
      "[24,    70] loss: 0.006\n",
      "train_loss = 0.003668, valid_loss = 0.039549\n",
      "\n",
      "[25,    10] loss: 0.003\n",
      "[25,    20] loss: 0.004\n",
      "[25,    30] loss: 0.004\n",
      "[25,    40] loss: 0.003\n",
      "[25,    50] loss: 0.005\n",
      "[25,    60] loss: 0.006\n",
      "[25,    70] loss: 0.009\n",
      "train_loss = 0.006769, valid_loss = 0.046785\n",
      "\n",
      "[26,    10] loss: 0.008\n",
      "[26,    20] loss: 0.004\n",
      "[26,    30] loss: 0.004\n",
      "[26,    40] loss: 0.004\n",
      "[26,    50] loss: 0.003\n",
      "[26,    60] loss: 0.003\n",
      "[26,    70] loss: 0.003\n",
      "train_loss = 0.003549, valid_loss = 0.042493\n",
      "\n",
      "[27,    10] loss: 0.003\n",
      "[27,    20] loss: 0.010\n",
      "[27,    30] loss: 0.007\n",
      "[27,    40] loss: 0.003\n",
      "[27,    50] loss: 0.004\n",
      "[27,    60] loss: 0.003\n",
      "[27,    70] loss: 0.003\n",
      "train_loss = 0.003681, valid_loss = 0.046682\n",
      "\n",
      "[28,    10] loss: 0.003\n",
      "[28,    20] loss: 0.003\n",
      "[28,    30] loss: 0.006\n",
      "[28,    40] loss: 0.004\n",
      "[28,    50] loss: 0.002\n",
      "[28,    60] loss: 0.005\n",
      "[28,    70] loss: 0.003\n",
      "train_loss = 0.005161, valid_loss = 0.044397\n",
      "\n",
      "[29,    10] loss: 0.002\n",
      "[29,    20] loss: 0.003\n",
      "[29,    30] loss: 0.002\n",
      "[29,    40] loss: 0.002\n",
      "[29,    50] loss: 0.003\n",
      "[29,    60] loss: 0.008\n",
      "[29,    70] loss: 0.016\n",
      "train_loss = 0.007448, valid_loss = 0.051551\n",
      "\n",
      "[30,    10] loss: 0.009\n",
      "[30,    20] loss: 0.002\n",
      "[30,    30] loss: 0.006\n",
      "[30,    40] loss: 0.008\n",
      "[30,    50] loss: 0.003\n",
      "[30,    60] loss: 0.004\n",
      "[30,    70] loss: 0.005\n",
      "train_loss = 0.005140, valid_loss = 0.048472\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel2(dtype, num_in_features, num_out_features, dropout_rate=0.1)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoAModel3(nn.Module):\n",
    "    def __init__(self, dtype, num_in_features, num_out_featuers, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_in_features),\n",
    "\n",
    "            nn.Linear(num_in_features, 600),\n",
    "            nn.BatchNorm1d(600),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(600, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(400, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(100, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(50, 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(20, num_out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.554\n",
      "[1,    20] loss: 0.435\n",
      "[1,    30] loss: 0.375\n",
      "[1,    40] loss: 0.327\n",
      "[1,    50] loss: 0.293\n",
      "[1,    60] loss: 0.271\n",
      "[1,    70] loss: 0.238\n",
      "train_loss = 0.218866, valid_loss = 0.222320\n",
      "\n",
      "[2,    10] loss: 0.205\n",
      "[2,    20] loss: 0.191\n",
      "[2,    30] loss: 0.182\n",
      "[2,    40] loss: 0.168\n",
      "[2,    50] loss: 0.160\n",
      "[2,    60] loss: 0.142\n",
      "[2,    70] loss: 0.138\n",
      "train_loss = 0.127568, valid_loss = 0.132154\n",
      "\n",
      "[3,    10] loss: 0.125\n",
      "[3,    20] loss: 0.111\n",
      "[3,    30] loss: 0.116\n",
      "[3,    40] loss: 0.100\n",
      "[3,    50] loss: 0.101\n",
      "[3,    60] loss: 0.092\n",
      "[3,    70] loss: 0.084\n",
      "train_loss = 0.082615, valid_loss = 0.087189\n",
      "\n",
      "[4,    10] loss: 0.085\n",
      "[4,    20] loss: 0.073\n",
      "[4,    30] loss: 0.080\n",
      "[4,    40] loss: 0.064\n",
      "[4,    50] loss: 0.063\n",
      "[4,    60] loss: 0.069\n",
      "[4,    70] loss: 0.059\n",
      "train_loss = 0.061684, valid_loss = 0.066448\n",
      "\n",
      "[5,    10] loss: 0.054\n",
      "[5,    20] loss: 0.054\n",
      "[5,    30] loss: 0.055\n",
      "[5,    40] loss: 0.065\n",
      "[5,    50] loss: 0.048\n",
      "[5,    60] loss: 0.052\n",
      "[5,    70] loss: 0.056\n",
      "train_loss = 0.050464, valid_loss = 0.054698\n",
      "\n",
      "[6,    10] loss: 0.049\n",
      "[6,    20] loss: 0.049\n",
      "[6,    30] loss: 0.045\n",
      "[6,    40] loss: 0.045\n",
      "[6,    50] loss: 0.046\n",
      "[6,    60] loss: 0.042\n",
      "[6,    70] loss: 0.041\n",
      "train_loss = 0.042673, valid_loss = 0.048474\n",
      "\n",
      "[7,    10] loss: 0.045\n",
      "[7,    20] loss: 0.043\n",
      "[7,    30] loss: 0.039\n",
      "[7,    40] loss: 0.045\n",
      "[7,    50] loss: 0.040\n",
      "[7,    60] loss: 0.035\n",
      "[7,    70] loss: 0.037\n",
      "train_loss = 0.037756, valid_loss = 0.044554\n",
      "\n",
      "[8,    10] loss: 0.039\n",
      "[8,    20] loss: 0.038\n",
      "[8,    30] loss: 0.040\n",
      "[8,    40] loss: 0.038\n",
      "[8,    50] loss: 0.040\n",
      "[8,    60] loss: 0.035\n",
      "[8,    70] loss: 0.037\n",
      "train_loss = 0.033759, valid_loss = 0.042957\n",
      "\n",
      "[9,    10] loss: 0.036\n",
      "[9,    20] loss: 0.032\n",
      "[9,    30] loss: 0.025\n",
      "[9,    40] loss: 0.032\n",
      "[9,    50] loss: 0.031\n",
      "[9,    60] loss: 0.038\n",
      "[9,    70] loss: 0.025\n",
      "train_loss = 0.031980, valid_loss = 0.042536\n",
      "\n",
      "[10,    10] loss: 0.024\n",
      "[10,    20] loss: 0.027\n",
      "[10,    30] loss: 0.025\n",
      "[10,    40] loss: 0.019\n",
      "[10,    50] loss: 0.035\n",
      "[10,    60] loss: 0.030\n",
      "[10,    70] loss: 0.034\n",
      "train_loss = 0.020875, valid_loss = 0.040611\n",
      "\n",
      "[11,    10] loss: 0.017\n",
      "[11,    20] loss: 0.019\n",
      "[11,    30] loss: 0.021\n",
      "[11,    40] loss: 0.024\n",
      "[11,    50] loss: 0.024\n",
      "[11,    60] loss: 0.021\n",
      "[11,    70] loss: 0.020\n",
      "train_loss = 0.015775, valid_loss = 0.039432\n",
      "\n",
      "[12,    10] loss: 0.019\n",
      "[12,    20] loss: 0.016\n",
      "[12,    30] loss: 0.019\n",
      "[12,    40] loss: 0.017\n",
      "[12,    50] loss: 0.021\n",
      "[12,    60] loss: 0.018\n",
      "[12,    70] loss: 0.015\n",
      "train_loss = 0.015036, valid_loss = 0.038601\n",
      "\n",
      "[13,    10] loss: 0.016\n",
      "[13,    20] loss: 0.012\n",
      "[13,    30] loss: 0.009\n",
      "[13,    40] loss: 0.013\n",
      "[13,    50] loss: 0.017\n",
      "[13,    60] loss: 0.016\n",
      "[13,    70] loss: 0.015\n",
      "train_loss = 0.012495, valid_loss = 0.044429\n",
      "\n",
      "[14,    10] loss: 0.013\n",
      "[14,    20] loss: 0.010\n",
      "[14,    30] loss: 0.008\n",
      "[14,    40] loss: 0.011\n",
      "[14,    50] loss: 0.010\n",
      "[14,    60] loss: 0.013\n",
      "[14,    70] loss: 0.010\n",
      "train_loss = 0.013055, valid_loss = 0.050584\n",
      "\n",
      "[15,    10] loss: 0.007\n",
      "[15,    20] loss: 0.015\n",
      "[15,    30] loss: 0.013\n",
      "[15,    40] loss: 0.011\n",
      "[15,    50] loss: 0.013\n",
      "[15,    60] loss: 0.012\n",
      "[15,    70] loss: 0.012\n",
      "train_loss = 0.009669, valid_loss = 0.041363\n",
      "\n",
      "[16,    10] loss: 0.007\n",
      "[16,    20] loss: 0.006\n",
      "[16,    30] loss: 0.010\n",
      "[16,    40] loss: 0.008\n",
      "[16,    50] loss: 0.007\n",
      "[16,    60] loss: 0.009\n",
      "[16,    70] loss: 0.009\n",
      "train_loss = 0.010584, valid_loss = 0.040130\n",
      "\n",
      "[17,    10] loss: 0.009\n",
      "[17,    20] loss: 0.008\n",
      "[17,    30] loss: 0.013\n",
      "[17,    40] loss: 0.009\n",
      "[17,    50] loss: 0.012\n",
      "[17,    60] loss: 0.010\n",
      "[17,    70] loss: 0.007\n",
      "train_loss = 0.007074, valid_loss = 0.047471\n",
      "\n",
      "[18,    10] loss: 0.010\n",
      "[18,    20] loss: 0.011\n",
      "[18,    30] loss: 0.014\n",
      "[18,    40] loss: 0.011\n",
      "[18,    50] loss: 0.009\n",
      "[18,    60] loss: 0.009\n",
      "[18,    70] loss: 0.007\n",
      "train_loss = 0.006647, valid_loss = 0.040272\n",
      "\n",
      "[19,    10] loss: 0.011\n",
      "[19,    20] loss: 0.006\n",
      "[19,    30] loss: 0.009\n",
      "[19,    40] loss: 0.008\n",
      "[19,    50] loss: 0.005\n",
      "[19,    60] loss: 0.005\n",
      "[19,    70] loss: 0.008\n",
      "train_loss = 0.005004, valid_loss = 0.040372\n",
      "\n",
      "[20,    10] loss: 0.003\n",
      "[20,    20] loss: 0.007\n",
      "[20,    30] loss: 0.004\n",
      "[20,    40] loss: 0.008\n",
      "[20,    50] loss: 0.004\n",
      "[20,    60] loss: 0.006\n",
      "[20,    70] loss: 0.005\n",
      "train_loss = 0.007369, valid_loss = 0.044047\n",
      "\n",
      "[21,    10] loss: 0.004\n",
      "[21,    20] loss: 0.003\n",
      "[21,    30] loss: 0.004\n",
      "[21,    40] loss: 0.003\n",
      "[21,    50] loss: 0.007\n",
      "[21,    60] loss: 0.003\n",
      "[21,    70] loss: 0.003\n",
      "train_loss = 0.003827, valid_loss = 0.040986\n",
      "\n",
      "[22,    10] loss: 0.005\n",
      "[22,    20] loss: 0.006\n",
      "[22,    30] loss: 0.004\n",
      "[22,    40] loss: 0.003\n",
      "[22,    50] loss: 0.003\n",
      "[22,    60] loss: 0.002\n",
      "[22,    70] loss: 0.004\n",
      "train_loss = 0.003581, valid_loss = 0.043670\n",
      "\n",
      "[23,    10] loss: 0.004\n",
      "[23,    20] loss: 0.004\n",
      "[23,    30] loss: 0.004\n",
      "[23,    40] loss: 0.007\n",
      "[23,    50] loss: 0.006\n",
      "[23,    60] loss: 0.005\n",
      "[23,    70] loss: 0.003\n",
      "train_loss = 0.003309, valid_loss = 0.043062\n",
      "\n",
      "[24,    10] loss: 0.007\n",
      "[24,    20] loss: 0.007\n",
      "[24,    30] loss: 0.009\n",
      "[24,    40] loss: 0.005\n",
      "[24,    50] loss: 0.005\n",
      "[24,    60] loss: 0.008\n",
      "[24,    70] loss: 0.015\n",
      "train_loss = 0.004608, valid_loss = 0.045565\n",
      "\n",
      "[25,    10] loss: 0.005\n",
      "[25,    20] loss: 0.003\n",
      "[25,    30] loss: 0.003\n",
      "[25,    40] loss: 0.003\n",
      "[25,    50] loss: 0.002\n",
      "[25,    60] loss: 0.004\n",
      "[25,    70] loss: 0.005\n",
      "train_loss = 0.002401, valid_loss = 0.040664\n",
      "\n",
      "[26,    10] loss: 0.004\n",
      "[26,    20] loss: 0.002\n",
      "[26,    30] loss: 0.002\n",
      "[26,    40] loss: 0.002\n",
      "[26,    50] loss: 0.002\n",
      "[26,    60] loss: 0.002\n",
      "[26,    70] loss: 0.005\n",
      "train_loss = 0.002380, valid_loss = 0.044329\n",
      "\n",
      "[27,    10] loss: 0.007\n",
      "[27,    20] loss: 0.003\n",
      "[27,    30] loss: 0.006\n",
      "[27,    40] loss: 0.007\n",
      "[27,    50] loss: 0.009\n",
      "[27,    60] loss: 0.004\n",
      "[27,    70] loss: 0.003\n",
      "train_loss = 0.003335, valid_loss = 0.045266\n",
      "\n",
      "[28,    10] loss: 0.002\n",
      "[28,    20] loss: 0.003\n",
      "[28,    30] loss: 0.004\n",
      "[28,    40] loss: 0.005\n",
      "[28,    50] loss: 0.007\n",
      "[28,    60] loss: 0.003\n",
      "[28,    70] loss: 0.013\n",
      "train_loss = 0.006469, valid_loss = 0.044755\n",
      "\n",
      "[29,    10] loss: 0.007\n",
      "[29,    20] loss: 0.006\n",
      "[29,    30] loss: 0.005\n",
      "[29,    40] loss: 0.005\n",
      "[29,    50] loss: 0.006\n",
      "[29,    60] loss: 0.003\n",
      "[29,    70] loss: 0.004\n",
      "train_loss = 0.003500, valid_loss = 0.044464\n",
      "\n",
      "[30,    10] loss: 0.004\n",
      "[30,    20] loss: 0.004\n",
      "[30,    30] loss: 0.002\n",
      "[30,    40] loss: 0.005\n",
      "[30,    50] loss: 0.005\n",
      "[30,    60] loss: 0.006\n",
      "[30,    70] loss: 0.008\n",
      "train_loss = 0.003283, valid_loss = 0.043025\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel3(dtype, num_in_features, num_out_features, dropout_rate=0.1)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "epoches = [i for i in range(30)]\n",
    "\n",
    "for epoch in epoches:  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(epoches, train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MoAModel4(nn.Module):\n",
    "    def __init__(self, dtype, num_in_features, num_out_featuers, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_in_features),\n",
    "\n",
    "            nn.Linear(num_in_features, 600),\n",
    "            nn.BatchNorm1d(600),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(600, 400),\n",
    "            nn.BatchNorm1d(400),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(400, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.BatchNorm1d(100),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(100, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(50, 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(20, num_out_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.607\n",
      "[1,    20] loss: 0.494\n",
      "[1,    30] loss: 0.433\n",
      "[1,    40] loss: 0.393\n",
      "[1,    50] loss: 0.369\n",
      "[1,    60] loss: 0.336\n",
      "[1,    70] loss: 0.308\n",
      "train_loss = 0.285819, valid_loss = 0.288053\n",
      "\n",
      "[2,    10] loss: 0.277\n",
      "[2,    20] loss: 0.257\n",
      "[2,    30] loss: 0.239\n",
      "[2,    40] loss: 0.219\n",
      "[2,    50] loss: 0.201\n",
      "[2,    60] loss: 0.191\n",
      "[2,    70] loss: 0.181\n",
      "train_loss = 0.165511, valid_loss = 0.169032\n",
      "\n",
      "[3,    10] loss: 0.158\n",
      "[3,    20] loss: 0.152\n",
      "[3,    30] loss: 0.135\n",
      "[3,    40] loss: 0.133\n",
      "[3,    50] loss: 0.131\n",
      "[3,    60] loss: 0.116\n",
      "[3,    70] loss: 0.108\n",
      "train_loss = 0.101247, valid_loss = 0.105967\n",
      "\n",
      "[4,    10] loss: 0.093\n",
      "[4,    20] loss: 0.094\n",
      "[4,    30] loss: 0.095\n",
      "[4,    40] loss: 0.091\n",
      "[4,    50] loss: 0.081\n",
      "[4,    60] loss: 0.075\n",
      "[4,    70] loss: 0.076\n",
      "train_loss = 0.069874, valid_loss = 0.074957\n",
      "\n",
      "[5,    10] loss: 0.075\n",
      "[5,    20] loss: 0.063\n",
      "[5,    30] loss: 0.066\n",
      "[5,    40] loss: 0.057\n",
      "[5,    50] loss: 0.062\n",
      "[5,    60] loss: 0.055\n",
      "[5,    70] loss: 0.053\n",
      "train_loss = 0.051994, valid_loss = 0.059098\n",
      "\n",
      "[6,    10] loss: 0.050\n",
      "[6,    20] loss: 0.046\n",
      "[6,    30] loss: 0.047\n",
      "[6,    40] loss: 0.044\n",
      "[6,    50] loss: 0.041\n",
      "[6,    60] loss: 0.047\n",
      "[6,    70] loss: 0.048\n",
      "train_loss = 0.037666, valid_loss = 0.050292\n",
      "\n",
      "[7,    10] loss: 0.038\n",
      "[7,    20] loss: 0.042\n",
      "[7,    30] loss: 0.035\n",
      "[7,    40] loss: 0.035\n",
      "[7,    50] loss: 0.033\n",
      "[7,    60] loss: 0.036\n",
      "[7,    70] loss: 0.034\n",
      "train_loss = 0.033117, valid_loss = 0.044792\n",
      "\n",
      "[8,    10] loss: 0.028\n",
      "[8,    20] loss: 0.035\n",
      "[8,    30] loss: 0.025\n",
      "[8,    40] loss: 0.032\n",
      "[8,    50] loss: 0.035\n",
      "[8,    60] loss: 0.029\n",
      "[8,    70] loss: 0.025\n",
      "train_loss = 0.025087, valid_loss = 0.042105\n",
      "\n",
      "[9,    10] loss: 0.026\n",
      "[9,    20] loss: 0.026\n",
      "[9,    30] loss: 0.023\n",
      "[9,    40] loss: 0.022\n",
      "[9,    50] loss: 0.026\n",
      "[9,    60] loss: 0.025\n",
      "[9,    70] loss: 0.028\n",
      "train_loss = 0.019411, valid_loss = 0.041445\n",
      "\n",
      "[10,    10] loss: 0.018\n",
      "[10,    20] loss: 0.017\n",
      "[10,    30] loss: 0.017\n",
      "[10,    40] loss: 0.019\n",
      "[10,    50] loss: 0.018\n",
      "[10,    60] loss: 0.017\n",
      "[10,    70] loss: 0.026\n",
      "train_loss = 0.016644, valid_loss = 0.038780\n",
      "\n",
      "[11,    10] loss: 0.017\n",
      "[11,    20] loss: 0.016\n",
      "[11,    30] loss: 0.016\n",
      "[11,    40] loss: 0.013\n",
      "[11,    50] loss: 0.014\n",
      "[11,    60] loss: 0.016\n",
      "[11,    70] loss: 0.020\n",
      "train_loss = 0.011642, valid_loss = 0.037830\n",
      "\n",
      "[12,    10] loss: 0.013\n",
      "[12,    20] loss: 0.023\n",
      "[12,    30] loss: 0.019\n",
      "[12,    40] loss: 0.013\n",
      "[12,    50] loss: 0.011\n",
      "[12,    60] loss: 0.022\n",
      "[12,    70] loss: 0.013\n",
      "train_loss = 0.017156, valid_loss = 0.040508\n",
      "\n",
      "[13,    10] loss: 0.012\n",
      "[13,    20] loss: 0.013\n",
      "[13,    30] loss: 0.014\n",
      "[13,    40] loss: 0.009\n",
      "[13,    50] loss: 0.010\n",
      "[13,    60] loss: 0.012\n",
      "[13,    70] loss: 0.014\n",
      "train_loss = 0.014850, valid_loss = 0.040938\n",
      "\n",
      "[14,    10] loss: 0.017\n",
      "[14,    20] loss: 0.016\n",
      "[14,    30] loss: 0.020\n",
      "[14,    40] loss: 0.009\n",
      "[14,    50] loss: 0.009\n",
      "[14,    60] loss: 0.007\n",
      "[14,    70] loss: 0.009\n",
      "train_loss = 0.008684, valid_loss = 0.037855\n",
      "\n",
      "[15,    10] loss: 0.007\n",
      "[15,    20] loss: 0.006\n",
      "[15,    30] loss: 0.008\n",
      "[15,    40] loss: 0.008\n",
      "[15,    50] loss: 0.005\n",
      "[15,    60] loss: 0.009\n",
      "[15,    70] loss: 0.006\n",
      "train_loss = 0.004825, valid_loss = 0.039489\n",
      "\n",
      "[16,    10] loss: 0.004\n",
      "[16,    20] loss: 0.006\n",
      "[16,    30] loss: 0.008\n",
      "[16,    40] loss: 0.006\n",
      "[16,    50] loss: 0.005\n",
      "[16,    60] loss: 0.004\n",
      "[16,    70] loss: 0.005\n",
      "train_loss = 0.005556, valid_loss = 0.038058\n",
      "\n",
      "[17,    10] loss: 0.005\n",
      "[17,    20] loss: 0.010\n",
      "[17,    30] loss: 0.007\n",
      "[17,    40] loss: 0.005\n",
      "[17,    50] loss: 0.006\n",
      "[17,    60] loss: 0.005\n",
      "[17,    70] loss: 0.004\n",
      "train_loss = 0.004028, valid_loss = 0.040250\n",
      "\n",
      "[18,    10] loss: 0.005\n",
      "[18,    20] loss: 0.006\n",
      "[18,    30] loss: 0.006\n",
      "[18,    40] loss: 0.004\n",
      "[18,    50] loss: 0.004\n",
      "[18,    60] loss: 0.005\n",
      "[18,    70] loss: 0.006\n",
      "train_loss = 0.003962, valid_loss = 0.037933\n",
      "\n",
      "[19,    10] loss: 0.006\n",
      "[19,    20] loss: 0.005\n",
      "[19,    30] loss: 0.004\n",
      "[19,    40] loss: 0.005\n",
      "[19,    50] loss: 0.007\n",
      "[19,    60] loss: 0.004\n",
      "[19,    70] loss: 0.003\n",
      "train_loss = 0.006341, valid_loss = 0.040137\n",
      "\n",
      "[20,    10] loss: 0.004\n",
      "[20,    20] loss: 0.003\n",
      "[20,    30] loss: 0.003\n",
      "[20,    40] loss: 0.003\n",
      "[20,    50] loss: 0.003\n",
      "[20,    60] loss: 0.003\n",
      "[20,    70] loss: 0.003\n",
      "train_loss = 0.003017, valid_loss = 0.039570\n",
      "\n",
      "[21,    10] loss: 0.002\n",
      "[21,    20] loss: 0.002\n",
      "[21,    30] loss: 0.003\n",
      "[21,    40] loss: 0.003\n",
      "[21,    50] loss: 0.005\n",
      "[21,    60] loss: 0.005\n",
      "[21,    70] loss: 0.010\n",
      "train_loss = 0.003735, valid_loss = 0.041557\n",
      "\n",
      "[22,    10] loss: 0.005\n",
      "[22,    20] loss: 0.003\n",
      "[22,    30] loss: 0.003\n",
      "[22,    40] loss: 0.002\n",
      "[22,    50] loss: 0.003\n",
      "[22,    60] loss: 0.002\n",
      "[22,    70] loss: 0.002\n",
      "train_loss = 0.002164, valid_loss = 0.041298\n",
      "\n",
      "[23,    10] loss: 0.004\n",
      "[23,    20] loss: 0.003\n",
      "[23,    30] loss: 0.003\n",
      "[23,    40] loss: 0.002\n",
      "[23,    50] loss: 0.002\n",
      "[23,    60] loss: 0.002\n",
      "[23,    70] loss: 0.003\n",
      "train_loss = 0.005920, valid_loss = 0.047218\n",
      "\n",
      "[24,    10] loss: 0.003\n",
      "[24,    20] loss: 0.004\n",
      "[24,    30] loss: 0.003\n",
      "[24,    40] loss: 0.004\n",
      "[24,    50] loss: 0.005\n",
      "[24,    60] loss: 0.002\n",
      "[24,    70] loss: 0.003\n",
      "train_loss = 0.005364, valid_loss = 0.043751\n",
      "\n",
      "[25,    10] loss: 0.003\n",
      "[25,    20] loss: 0.008\n",
      "[25,    30] loss: 0.002\n",
      "[25,    40] loss: 0.004\n",
      "[25,    50] loss: 0.002\n",
      "[25,    60] loss: 0.006\n",
      "[25,    70] loss: 0.003\n",
      "train_loss = 0.002078, valid_loss = 0.041257\n",
      "\n",
      "[26,    10] loss: 0.003\n",
      "[26,    20] loss: 0.005\n",
      "[26,    30] loss: 0.006\n",
      "[26,    40] loss: 0.002\n",
      "[26,    50] loss: 0.002\n",
      "[26,    60] loss: 0.003\n",
      "[26,    70] loss: 0.003\n",
      "train_loss = 0.002220, valid_loss = 0.040099\n",
      "\n",
      "[27,    10] loss: 0.003\n",
      "[27,    20] loss: 0.002\n",
      "[27,    30] loss: 0.002\n",
      "[27,    40] loss: 0.004\n",
      "[27,    50] loss: 0.002\n",
      "[27,    60] loss: 0.003\n",
      "[27,    70] loss: 0.004\n",
      "train_loss = 0.002127, valid_loss = 0.041566\n",
      "\n",
      "[28,    10] loss: 0.002\n",
      "[28,    20] loss: 0.004\n",
      "[28,    30] loss: 0.002\n",
      "[28,    40] loss: 0.005\n",
      "[28,    50] loss: 0.004\n",
      "[28,    60] loss: 0.007\n",
      "[28,    70] loss: 0.004\n",
      "train_loss = 0.001957, valid_loss = 0.043387\n",
      "\n",
      "[29,    10] loss: 0.002\n",
      "[29,    20] loss: 0.002\n",
      "[29,    30] loss: 0.003\n",
      "[29,    40] loss: 0.002\n",
      "[29,    50] loss: 0.006\n",
      "[29,    60] loss: 0.002\n",
      "[29,    70] loss: 0.005\n",
      "train_loss = 0.004871, valid_loss = 0.045938\n",
      "\n",
      "[30,    10] loss: 0.005\n",
      "[30,    20] loss: 0.007\n",
      "[30,    30] loss: 0.007\n",
      "[30,    40] loss: 0.005\n",
      "[30,    50] loss: 0.011\n",
      "[30,    60] loss: 0.004\n",
      "[30,    70] loss: 0.004\n",
      "train_loss = 0.003185, valid_loss = 0.044045\n",
      "\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_in_features = X_trn.shape[1]\n",
    "# num_hidden_features = 10\n",
    "num_out_features = 1\n",
    "\n",
    "model = MoAModel4(dtype, num_in_features, num_out_features, dropout_rate=0.1)\n",
    "\n",
    "# print_every = 5\n",
    "max_epoch = 100\n",
    "lr = 1e-3\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "epoches = [i for i in range(30)]\n",
    "\n",
    "for epoch in epoches:  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    train_loss, valid_loss = evaluation(model, train_dataloader, valid_dataloader)\n",
    "    print('train_loss = %f, valid_loss = %f\\n' % (train_loss, valid_loss))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(epoches, train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
